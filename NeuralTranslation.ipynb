{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuralTranslation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7ptvyA43oiM"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib.ticker as ticker\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "import unicodedata\r\n",
        "import re\r\n",
        "import numpy as np\r\n",
        "import os\r\n",
        "import io\r\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkAPN97F30_n"
      },
      "source": [
        "path_to_file=\"hin.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4s201V54CMC"
      },
      "source": [
        "#to convert unicode to ascii\r\n",
        "def unicode_to_ascii(s):\r\n",
        "    text = s.encode('utf-8').decode('utf-8')\r\n",
        "    return text\r\n",
        "#preprcessing with turning specific characters\r\n",
        "def preprocess_sentence(w):\r\n",
        "    w = unicode_to_ascii(w.lower().strip())\r\n",
        "\r\n",
        "    # creating a space between a word and the punctuation following it\r\n",
        "    # eg: \"he is a boy.\" => \"he is a boy .\"\r\n",
        "    # Reference:- https://stackoverflow.com/questions/3645931/python-padding-punctuation-with-white-spaces-keeping-punctuation\r\n",
        "    w = re.sub(r\"([?.!,¿])\", r\" \\1 \", w)\r\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\r\n",
        "\r\n",
        "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\r\n",
        "\r\n",
        "    w = w.strip()\r\n",
        "\r\n",
        "    # adding a start and an end token to the sentence\r\n",
        "    # so that the model know when to start and stop predicting.\r\n",
        "    w = '<start> ' + w + ' <end>'\r\n",
        "    return w    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gb4NXbKd4EYG",
        "outputId": "c3c2dacf-8a29-4fc7-be11-6de3f8aeb530"
      },
      "source": [
        "en_sentence = u\"May I borrow this book?\"\r\n",
        "hn_sentence = u\"क्या मैं यह पुस्तक उधार ले सकता हूँ?\"\r\n",
        "print(preprocess_sentence(en_sentence))\r\n",
        "print(preprocess_sentence(hn_sentence))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> may i borrow this book ? <end>\n",
            "<start> क्या मैं यह पुस्तक उधार ले सकता हूँ ? <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_nhGXb-J4GXP"
      },
      "source": [
        "\"\"\"\r\n",
        "1.Remove the accents\r\n",
        "2.clean the sentences\r\n",
        "3.Return the sentense in this seq[English,German]\r\n",
        "\"\"\"\r\n",
        "def create_dataset(path,num_examples):\r\n",
        "    lines=io.open(path,encoding='UTF-8').read().strip().split('\\n')\r\n",
        "    \r\n",
        "    \r\n",
        "    word_pairs = [[preprocess_sentence(w) for w in l.split('\\t')]  for l in lines[:num_examples]]\r\n",
        "    \r\n",
        "    return zip(*word_pairs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjGbquCG4ICa",
        "outputId": "bcb64ff6-9dbd-475e-a597-538e0dca0008"
      },
      "source": [
        "en,hn,un = create_dataset(path_to_file,None)\r\n",
        "print(en[-1])\r\n",
        "print(hn[-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> when i was a kid , touching bugs didn't bother me a bit . now i can hardly stand looking at pictures of them . <end>\n",
            "<start> जब मैं बच्चा था , मुझे कीड़ों को छूने से कोई परेशानी नहीं होती थी , पर अब मैं उनकी तस्वीरें देखना भी बर्दाश्त नहीं कर सकता। <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owYZiyk24JgR"
      },
      "source": [
        "def tokenize(lang):\r\n",
        "    lang_tokenizer=tf.keras.preprocessing.text.Tokenizer(\r\n",
        "        filters=''\r\n",
        "    )\r\n",
        "    lang_tokenizer.fit_on_texts(lang)\r\n",
        "    tensors = lang_tokenizer.texts_to_sequences(lang)\r\n",
        "    tensors = tf.keras.preprocessing.sequence.pad_sequences(tensors,padding='post')\r\n",
        "    \r\n",
        "    return tensors,lang_tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0EqU5NEC4Ln3"
      },
      "source": [
        "#defning the load datase function that will carry all the above three functions:)\r\n",
        "def load_dataset(path,num_examples=None):\r\n",
        "    inp_lang,targ_lang,unwanted = create_dataset(path,num_examples)\r\n",
        "    \r\n",
        "    input_tensor,input_language_tokenizer = tokenize(inp_lang)\r\n",
        "    target_tensor,targ_lang_tokenizer = tokenize(targ_lang)\r\n",
        "    \r\n",
        "    return input_tensor,target_tensor,input_language_tokenizer,targ_lang_tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DAEnunrL4NKr"
      },
      "source": [
        "\"\"\"\r\n",
        "limiting the examples so that training can be faster\r\n",
        "there are >100000 sentences in data set to compile we are selecting\r\n",
        "40000 but compromising the the quality \r\n",
        "TODO change the num example to None in releasing patterns\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "num_examples=None\r\n",
        "input_tensor,target_tensor,inp_lang,targ_lang = load_dataset(path_to_file,num_examples)\r\n",
        "\r\n",
        "#max length of target tensors\r\n",
        "max_length_targ,max_length_inp = target_tensor.shape[1],input_tensor.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nxg19hXE4PL-",
        "outputId": "2ddec5f6-57b9-480b-8bad-fbd4ad0d09a8"
      },
      "source": [
        "#creating bacthes for training and validation \r\n",
        "input_tensor_train, input_tensor_val, target_tensor_train, target_tensor_val = train_test_split(input_tensor, target_tensor, test_size=0.2)\r\n",
        "\r\n",
        "# Show length\r\n",
        "print(len(input_tensor_train), len(target_tensor_train), len(input_tensor_val), len(target_tensor_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2338 2338 585 585\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IS51-N5P4Q4o"
      },
      "source": [
        "def convert(lang, tensor):\r\n",
        "    for t in tensor:\r\n",
        "        if t!=0:\r\n",
        "            print (\"%d ----> %s\" % (t, lang.index_word[t]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CZyK0imm4SUJ",
        "outputId": "c36e983f-07f6-4fc3-8fbf-36a91a463a56"
      },
      "source": [
        "print (\"Input Language; index to word mapping\")\r\n",
        "convert(inp_lang, input_tensor_train[0])\r\n",
        "print ()\r\n",
        "print (\"Target Language; index to word mapping\")\r\n",
        "convert(targ_lang, target_tensor_train[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Language; index to word mapping\n",
            "1 ----> <start>\n",
            "19 ----> do\n",
            "7 ----> you\n",
            "17 ----> have\n",
            "718 ----> rice\n",
            "8 ----> ?\n",
            "2 ----> <end>\n",
            "\n",
            "Target Language; index to word mapping\n",
            "1 ----> <start>\n",
            "56 ----> तुम्हारे\n",
            "45 ----> पास\n",
            "811 ----> चावल\n",
            "12 ----> है\n",
            "11 ----> क्या\n",
            "4 ----> ?\n",
            "2 ----> <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl3CbnyH4Tt7"
      },
      "source": [
        "BUFFER_SIZE=len(input_tensor_train)\r\n",
        "BATCH_SIZE = 64\r\n",
        "steps_per_epoch = len(input_tensor_train)//BATCH_SIZE\r\n",
        "embedin_dim = 256\r\n",
        "units=1024\r\n",
        "vocab_inp_size=len(inp_lang.word_index)+1\r\n",
        "vocab_tar_size=len(targ_lang.word_index)+1\r\n",
        "\r\n",
        "\r\n",
        "dataset = tf.data.Dataset.from_tensor_slices((input_tensor_train,target_tensor_train)).shuffle(BUFFER_SIZE)\r\n",
        "dataset = dataset.batch(BATCH_SIZE,drop_remainder=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "isEMNW2B4XDa",
        "outputId": "26c35eb1-0291-4302-c9d3-95a623a1d811"
      },
      "source": [
        "example_input_batch,example_target_batch = next(iter(dataset))\r\n",
        "example_input_batch.shape,example_target_batch.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 27]), TensorShape([64, 29]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-cH2P0V4Zgd"
      },
      "source": [
        "class Encoder(tf.keras.Model):\r\n",
        "    def __init__(self,vocab_size,embedding_dim,enc_units,batch_sz):\r\n",
        "        super(Encoder,self).__init__()\r\n",
        "        self.batch_sz = batch_sz\r\n",
        "        self.enc_units = enc_units\r\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size,embedin_dim)\r\n",
        "        self.gru = tf.keras.layers.GRU(\r\n",
        "            self.enc_units,\r\n",
        "            return_sequences=True,\r\n",
        "            return_state=True,\r\n",
        "            recurrent_initializer='glorot_uniform'\r\n",
        "        )\r\n",
        "        \r\n",
        "    def call(self,x,hidden):\r\n",
        "        #x is our input\r\n",
        "        x=self.embedding(x)\r\n",
        "        output,state = self.gru(x,initial_state=hidden)\r\n",
        "        return output,state\r\n",
        "    def initialize_hidden_state(self):\r\n",
        "        return tf.zeros((self.batch_sz,self.enc_units))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYGsGOJR4a3x"
      },
      "source": [
        "encoder = Encoder(vocab_inp_size,embedin_dim,units,BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "APzFcSQX4chY",
        "outputId": "6c55d307-438f-4644-b7ea-1ca6a4e369d3"
      },
      "source": [
        "#sample to check the layers are working \r\n",
        "sample_hidden = encoder.initialize_hidden_state()\r\n",
        "sample_output,sample_hidden = encoder(example_input_batch,sample_hidden)\r\n",
        "\r\n",
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\r\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 27, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GNyBgGo4gqV"
      },
      "source": [
        "# I am Using the Bahdanau Attention for encoding the parameters are:-\r\n",
        "* FC = Fully connected (dense) layer\r\n",
        "* EO = Encoder output\r\n",
        "* H = hidden state\r\n",
        "* X = input to the decoder\r\n",
        "* The pseudo code for each is:-\r\n",
        "* 1)score = FC(tanh(FC(EO) + FC(H)))\r\n",
        "* 2)attention weights = softmax(score, axis = 1)\r\n",
        "* 3)context vector = sum(attention weights * EO, axis = 1)\r\n",
        "* 4)embedding output = It is got from the input passed to the Decoder Embedding Layer.\r\n",
        "* 5)merged vector = concat(embedding output, context vector)\r\n",
        "* note:-\r\n",
        "* This merged vector is then passed to gru layer as hidden state\r\n",
        "* note:-\r\n",
        "* axis=1 is there because we have to make change accross the max_len field so we took axis 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8pAhUPzz4dqz"
      },
      "source": [
        "class BahdanauAttention(tf.keras.layers.Layer):\r\n",
        "    def __init__(self,units):\r\n",
        "        super(BahdanauAttention,self).__init__()\r\n",
        "        self.w1=tf.keras.layers.Dense(units)\r\n",
        "        self.w2=tf.keras.layers.Dense(units)\r\n",
        "        self.V = tf.keras.layers.Dense(1)\r\n",
        "        \r\n",
        "    def call(self,query,values):\r\n",
        "        #we will be doing it to get addition along the time axis to calculate the score\r\n",
        "        query_with_time_axis = tf.expand_dims(query,1)\r\n",
        "        \r\n",
        "        #shape of the score will be(batchsize,maxlength,1)\r\n",
        "        #1 is because it is passing through the final dense layer having units ==1\r\n",
        "        # the shape of the tensor before applying self.V is (batch_size, max_length, units)\r\n",
        "        score = self.V(tf.nn.tanh(self.w1(query_with_time_axis)+self.w2(values)))\r\n",
        "        # attention_weights shape == (batch_size, max_length, 1)\r\n",
        "        attention_weights = tf.nn.softmax(score,axis=1)\r\n",
        "        # context_vector shape after sum == (batch_size, hidden_size)\r\n",
        "        context_vector=attention_weights * values\r\n",
        "        context_vector=tf.reduce_sum(context_vector,axis=1)\r\n",
        "        \r\n",
        "        return context_vector,attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-El59rpF4qsK",
        "outputId": "0e8ff252-8f9b-47b4-c055-dfc8d8cd975e"
      },
      "source": [
        "attention_layer = BahdanauAttention(10)\r\n",
        "attention_result,attention_weights=attention_layer(sample_hidden,sample_output)\r\n",
        "print(\"Attention result shape: (batch size, units) {}\".format(attention_result.shape))\r\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attention result shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 27, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUKeehOx4uNX"
      },
      "source": [
        "class Decoder(tf.keras.Model):\r\n",
        "    def __init__(self,vocab_size,embedding_dim,dec_units,batch_sz):\r\n",
        "        super(Decoder,self).__init__()\r\n",
        "        self.batch_sz=batch_sz\r\n",
        "        self.dec_units=dec_units\r\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size,embedding_dim)\r\n",
        "        self.gru=tf.keras.layers.GRU(\r\n",
        "            self.dec_units,\r\n",
        "            return_sequences=True,\r\n",
        "            return_state=True,\r\n",
        "            recurrent_initializer='glorot_uniform'\r\n",
        "        )\r\n",
        "        self.fc=tf.keras.layers.Dense(\r\n",
        "            vocab_size\r\n",
        "        )\r\n",
        "        \r\n",
        "        #used for attention\r\n",
        "        self.attention = BahdanauAttention(self.dec_units)\r\n",
        "    def call(self,x,hidden,enc_output):\r\n",
        "        context_vector,attention_weights=self.attention(hidden,enc_output)\r\n",
        "        \r\n",
        "        x=self.embedding(x)\r\n",
        "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\r\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\r\n",
        "        output,state = self.gru(x)\r\n",
        "        output=tf.reshape(output,(-1,output.shape[2]))\r\n",
        "        \r\n",
        "        x = self.fc(output)\r\n",
        "        \r\n",
        "        return x,state,attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZSHPQXc4wa8",
        "outputId": "495f4a71-6f76-48b9-f000-f2aaab47d56a"
      },
      "source": [
        "decoder = Decoder(vocab_tar_size, embedin_dim, units, BATCH_SIZE)\r\n",
        "\r\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\r\n",
        "                                      sample_hidden, sample_output)\r\n",
        "\r\n",
        "print ('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 3086)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4m8TUJ0m4x_i"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam()\r\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\r\n",
        "    from_logits=True,reduction='none'\r\n",
        ")\r\n",
        "def loss_function(real,pred):\r\n",
        "    mask = tf.math.logical_not(tf.math.equal(real,0))\r\n",
        "    loss_ = loss_object(real,pred)\r\n",
        "    \r\n",
        "    mask = tf.cast(mask,dtype=loss_.dtype)\r\n",
        "    loss_ *=mask\r\n",
        "    \r\n",
        "    return loss_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srvboxn94z3-"
      },
      "source": [
        "checkpoint_dir = 'training_checkpoints'\r\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\r\n",
        "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\r\n",
        "                                 encoder=encoder,\r\n",
        "                                 decoder=decoder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ubQyZi441VR"
      },
      "source": [
        "@tf.function\r\n",
        "def train_step(inp,targ,enc_hidden):\r\n",
        "    loss=0\r\n",
        "    #gradient tape is typically diffrention for complex tensors\r\n",
        "    with tf.GradientTape() as tape:\r\n",
        "        enc_output,enc_hidden=encoder(inp,enc_hidden)\r\n",
        "        dec_hidden = enc_hidden\r\n",
        "        dec_input = tf.expand_dims([targ_lang.word_index['<start>']] * BATCH_SIZE, 1)\r\n",
        "        \r\n",
        "        #using teacher forcing method to feed the target as next input\r\n",
        "        for t in range(1,targ.shape[1]):\r\n",
        "            #passing the enc_output to the decoder\r\n",
        "            predictions,dec_hidden,_=decoder(dec_input,dec_hidden,enc_output)\r\n",
        "            \r\n",
        "            loss +=loss_function(targ[:,t],predictions)\r\n",
        "            \r\n",
        "            dec_input = tf.expand_dims(targ[:,t],1)\r\n",
        "        batch_loss = (loss/int(targ.shape[1]))\r\n",
        "        variables = encoder.trainable_variables + decoder.trainable_variables\r\n",
        "        gradients = tape.gradient(loss,variables)\r\n",
        "        \r\n",
        "        optimizer.apply_gradients(zip(gradients,variables))\r\n",
        "        return batch_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PmhmQKd42zY",
        "outputId": "e5809570-3b50-4448-d53d-1ea5ea3cb79c"
      },
      "source": [
        "EPOCHS=50\r\n",
        "for epoch in range(EPOCHS):\r\n",
        "    start =time.time()\r\n",
        "    \r\n",
        "    enc_hidden = encoder.initialize_hidden_state()\r\n",
        "    total_loss=0\r\n",
        "    for (batch, (inp, targ)) in enumerate(dataset.take(steps_per_epoch)):\r\n",
        "        batch_loss = train_step(inp,targ,enc_hidden)\r\n",
        "        total_loss+=batch_loss\r\n",
        "        if batch %100==0:\r\n",
        "            print(f'Epoch {epoch + 1} Batch {batch} Loss {batch_loss.numpy()}')\r\n",
        "    if(epoch+1)%2==0:\r\n",
        "        checkpoint.save(file_prefix=checkpoint_prefix)\r\n",
        "        \r\n",
        "    print(f'Epoch {epoch + 1} Loss {total_loss / steps_per_epoch}')\r\n",
        "    print(f'Time taken for 1 epoch {time.time() - start} sec\\n')    "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss [2.7707522  2.493564   1.9399737  1.6622988  2.2166378  1.384514\n",
            " 1.6622847  2.2168763  1.3853357  1.3855157  3.3245633  2.2165074\n",
            " 1.1085348  2.7705598  2.4942806  2.4934049  1.3857857  1.6621665\n",
            " 2.2165315  3.6007357  1.9398619  3.3250663  0.83098847 3.324812\n",
            " 1.6616551  2.216163   2.7706997  2.4931977  3.8789527  1.3858458\n",
            " 2.4941764  2.216215   4.154664   3.3243818  2.2159696  2.7703588\n",
            " 4.43243    2.493514   1.6619762  1.9393227  1.6616756  2.4935462\n",
            " 1.9392676  2.215973   2.4936655  1.9393702  2.4929953  3.601253\n",
            " 2.7708766  1.9393842  3.0474362  1.9395077  2.4932873  1.9389938\n",
            " 2.4935644  1.6621485  2.2164943  1.6620538  1.3857011  3.3245587\n",
            " 1.9391993  2.4939022  4.4322352  2.4932673 ]\n",
            "Epoch 1 Loss [2.0150216 1.8196346 1.8931372 1.797775  1.7791157 1.7250419 1.9107745\n",
            " 1.8059281 1.6422907 1.9229444 1.9472661 1.8743371 1.8137025 1.7421769\n",
            " 1.9484313 1.886737  1.7773424 1.8563423 1.9572616 1.8851657 1.792235\n",
            " 2.116726  1.8671862 1.9431593 1.9000729 1.9510716 1.8040447 1.7259898\n",
            " 2.1688747 1.7903086 1.7552992 1.9161085 1.9438419 2.0044343 1.8302975\n",
            " 2.019187  2.0731854 1.8324844 1.6090885 1.7810228 1.690981  1.9763385\n",
            " 1.8018723 1.7764688 1.8682467 1.6699171 1.9475763 1.8524017 1.9718107\n",
            " 1.5675758 1.86552   1.7286841 1.8221196 1.9522432 1.8387547 1.6424565\n",
            " 1.9980912 2.015552  1.7491289 2.0443988 1.8358917 1.7474962 1.9886184\n",
            " 1.9090648]\n",
            "Time taken for 1 epoch 35.96480941772461 sec\n",
            "\n",
            "Epoch 2 Batch 0 Loss [2.095155   1.2115221  1.9706075  1.8901541  2.0594342  2.4025617\n",
            " 0.87802553 1.268627   1.389253   1.6197379  1.0205679  1.309567\n",
            " 0.6058367  1.774038   1.8265836  1.7833775  0.8742522  1.598518\n",
            " 1.6497751  0.94979477 1.7881875  1.5561209  1.1063886  2.4667606\n",
            " 2.1858273  2.2633886  1.6036463  2.0463438  1.1164994  1.5644974\n",
            " 1.4365507  0.80949223 0.7305339  1.2126194  0.37693745 1.7045196\n",
            " 3.6124883  1.1379279  2.6073635  1.2450864  1.4677826  1.3403735\n",
            " 1.6700597  1.4811002  1.8958114  1.5898616  1.4563856  1.5481931\n",
            " 1.8553386  1.317931   1.2579749  1.3068328  1.7258189  0.8468114\n",
            " 1.528142   1.7200714  1.6092608  1.1072797  1.7962524  1.8778021\n",
            " 1.7651339  2.548981   3.3502665  1.1512923 ]\n",
            "Epoch 2 Loss [1.5907124 1.4555568 1.6525787 1.458078  1.6661963 1.463882  1.6738586\n",
            " 1.5102404 1.5120097 1.7750983 1.645538  1.5921862 1.8065516 1.5898337\n",
            " 1.641812  1.5915896 1.5285639 1.7262646 1.797475  1.665247  1.4490798\n",
            " 1.5615311 1.4737324 1.5383824 1.6753663 1.5990716 1.6158494 1.4088058\n",
            " 1.4139545 1.5180281 1.530332  1.4915124 1.59057   1.4816091 1.4206729\n",
            " 1.6393783 1.6567978 1.5152408 1.4044032 1.51294   1.6936866 1.4620156\n",
            " 1.538038  1.6575568 1.5375756 1.5021899 1.5143237 1.6846678 1.5992517\n",
            " 1.4405884 1.6125934 1.4338089 1.5755193 1.631875  1.5766381 1.5275316\n",
            " 1.4126171 1.6048944 1.6503016 1.5282178 1.7071981 1.4376613 1.6479851\n",
            " 1.565713 ]\n",
            "Time taken for 1 epoch 8.061073064804077 sec\n",
            "\n",
            "Epoch 3 Batch 0 Loss [1.6316757  1.4933053  2.8491418  2.1766596  1.1568193  1.2373563\n",
            " 1.3961045  1.9414264  2.31788    1.5235332  1.3018494  1.9039469\n",
            " 1.8955075  2.8083613  1.66104    1.9613866  1.4385631  0.7940144\n",
            " 2.0667226  2.1158004  2.8219714  2.7002735  1.016138   0.8397486\n",
            " 1.4222252  0.660062   1.1027522  3.1744964  1.620808   1.1540833\n",
            " 1.5051847  1.3307168  3.1747878  1.4175518  1.0718951  0.8326618\n",
            " 1.9825152  1.0239078  1.3020277  1.4131063  1.1033976  2.0677795\n",
            " 0.7086672  0.7702702  1.3830597  1.8910401  0.97119194 0.3942603\n",
            " 1.2263615  1.684072   1.9517479  1.427926   1.0956123  0.98951554\n",
            " 0.86233914 1.1338041  1.0465823  1.1160852  1.9949648  1.5213772\n",
            " 0.97862613 1.1778362  0.55573964 1.6393043 ]\n",
            "Epoch 3 Loss [1.5229452 1.3955468 1.4208304 1.5864416 1.3843791 1.5956404 1.4842843\n",
            " 1.486443  1.4232686 1.5077187 1.4331629 1.4383563 1.1699182 1.41863\n",
            " 1.4304842 1.4349837 1.4156747 1.338663  1.6169629 1.4778641 1.5683295\n",
            " 1.2699893 1.4047467 1.3318808 1.4620228 1.5024964 1.4634585 1.4962491\n",
            " 1.4471973 1.5397393 1.3494811 1.4594369 1.4127396 1.2978617 1.3707213\n",
            " 1.4933892 1.3819541 1.3904258 1.7348228 1.5741763 1.374648  1.5430312\n",
            " 1.3687568 1.5141929 1.5966748 1.4786692 1.421711  1.3087031 1.4289345\n",
            " 1.4032218 1.5060401 1.4904685 1.5207311 1.3704194 1.4663771 1.4439607\n",
            " 1.47486   1.5957279 1.3748757 1.5705374 1.3558508 1.6070715 1.337299\n",
            " 1.4343432]\n",
            "Time taken for 1 epoch 7.630290746688843 sec\n",
            "\n",
            "Epoch 4 Batch 0 Loss [1.8114077  1.2637861  1.0411421  1.5739967  1.3569385  1.5602354\n",
            " 1.7192862  0.9529189  1.8420292  1.3650796  1.4358693  1.1246744\n",
            " 0.7632753  1.5101768  1.1152408  1.1746341  1.1016308  0.4775659\n",
            " 2.3927312  0.89470184 2.6093771  1.1526502  1.9848086  0.9467411\n",
            " 0.9227783  0.6412004  0.8478917  0.961135   1.3721592  1.5628544\n",
            " 1.0339885  1.5007328  0.55292594 1.3605547  1.5422524  0.7459805\n",
            " 1.4464734  2.167953   1.1946695  1.6490432  0.9001302  0.9585178\n",
            " 2.12364    1.3652837  0.9193487  1.2324055  1.4522468  1.344474\n",
            " 1.4704536  1.3535651  1.0935436  1.8057034  2.0916429  1.0241104\n",
            " 1.7142338  1.9166392  1.2971704  0.9908008  0.98845255 2.259036\n",
            " 1.8766942  1.0555695  1.7920661  1.1461489 ]\n",
            "Epoch 4 Loss [1.3301822 1.2486694 1.3117305 1.5359529 1.4244567 1.3157792 1.3472581\n",
            " 1.4299066 1.3020097 1.4174399 1.3912402 1.371395  1.3245825 1.3589653\n",
            " 1.5156431 1.3980061 1.2595102 1.2316133 1.4004815 1.249629  1.4471874\n",
            " 1.3775922 1.458066  1.4341005 1.3657815 1.3147452 1.302322  1.2739704\n",
            " 1.4528954 1.1310856 1.2888705 1.3628457 1.3461593 1.3763065 1.3769305\n",
            " 1.21441   1.2845252 1.5098386 1.3156776 1.273418  1.34547   1.3700757\n",
            " 1.3244708 1.3505249 1.4082246 1.4446737 1.3649297 1.3259702 1.4239701\n",
            " 1.2850009 1.3348144 1.369351  1.4030756 1.3596506 1.4288161 1.3837132\n",
            " 1.5362738 1.4025699 1.279551  1.3932111 1.4503881 1.645366  1.4135585\n",
            " 1.1908685]\n",
            "Time taken for 1 epoch 8.034694910049438 sec\n",
            "\n",
            "Epoch 5 Batch 0 Loss [1.520915   0.81928927 1.4654975  0.75561136 1.4981611  1.2338909\n",
            " 1.8681986  1.5399756  0.98975927 1.8610377  0.9538094  1.4742476\n",
            " 0.4887157  1.0601923  1.8021512  0.9756986  1.2992516  1.3810819\n",
            " 1.4230933  0.8139636  2.6942334  1.4645996  1.4510338  2.6643302\n",
            " 0.65696675 1.0631679  1.3667297  1.0308925  0.52526313 1.2272213\n",
            " 1.8616905  1.4024545  1.5619378  1.6986552  0.73181623 1.3294059\n",
            " 0.74713355 1.7211906  1.5255009  0.51807886 1.2358928  1.37156\n",
            " 1.5255461  1.8809938  0.751187   2.6599553  1.2314967  1.0888155\n",
            " 1.6386619  1.5895617  1.5612264  1.8041931  1.7424345  1.4189\n",
            " 0.5671112  0.88420975 1.9810152  0.77587044 0.5570411  1.7322527\n",
            " 1.1981481  1.1268259  1.0986959  0.8493005 ]\n",
            "Epoch 5 Loss [1.3578982 1.2983583 1.3042442 1.4341588 1.3342545 1.2213134 1.333735\n",
            " 1.3893795 1.2459867 1.1997999 1.1751121 1.3986893 1.1562052 1.1241326\n",
            " 1.181939  1.2795593 1.3483398 1.4199395 1.3807377 1.3890607 1.3861594\n",
            " 1.2897586 1.2906892 1.398965  1.3291259 1.4143447 1.2293792 1.3637923\n",
            " 1.1507264 1.2637028 1.347148  1.3543847 1.2685826 1.2816427 1.2933073\n",
            " 1.311656  1.2672688 1.3553891 1.3198123 1.2682366 1.3204907 1.1936675\n",
            " 1.214275  1.4407586 1.2850884 1.195602  1.2781504 1.2872016 1.2700527\n",
            " 1.2247987 1.3040173 1.3467084 1.4005562 1.2039424 1.1337733 1.168736\n",
            " 1.0599965 1.2056782 1.267981  1.3077953 1.3386848 1.2879274 1.2061629\n",
            " 1.2386141]\n",
            "Time taken for 1 epoch 7.688185214996338 sec\n",
            "\n",
            "Epoch 6 Batch 0 Loss [1.1138539  1.7476556  1.1832757  1.612612   1.3839124  0.47182524\n",
            " 1.510775   0.57284254 1.4993918  1.254116   0.67661506 1.0299058\n",
            " 2.0975323  2.1528714  0.9181627  0.79229355 1.3561451  2.1118722\n",
            " 1.5463068  0.8667494  1.9460064  1.6730021  1.2763757  0.71351373\n",
            " 0.7690346  0.9247107  1.0314273  1.4415694  1.2804942  0.877832\n",
            " 1.4119855  2.526912   2.0222476  1.0953703  0.51374215 2.0952952\n",
            " 1.384555   1.533592   2.468394   1.5087494  0.6995272  1.2319138\n",
            " 1.4072292  1.840395   0.9027347  1.2431467  0.9058706  1.018868\n",
            " 0.6862741  0.592855   1.3752632  0.65419024 1.5422398  0.6029442\n",
            " 0.7164154  1.5597287  1.000618   1.6481514  1.0556308  0.885876\n",
            " 0.5658435  1.5998763  1.5533032  1.6008109 ]\n",
            "Epoch 6 Loss [1.0617487 1.2823277 1.1000767 1.1366405 1.1959305 1.1862544 1.2152091\n",
            " 1.0246384 1.2467386 1.0280905 1.0927557 1.2561172 1.2936096 1.3113971\n",
            " 1.3047571 1.224666  1.2720903 1.4151217 1.1676688 1.2981054 1.0712879\n",
            " 1.215328  1.2986    1.18285   1.2207603 1.3080814 1.0871081 1.0471646\n",
            " 1.1330857 1.0918924 1.1561697 1.190441  1.0849566 1.2531075 1.1477948\n",
            " 1.2240865 1.1758081 1.3417891 1.2129958 1.2176421 1.3570312 1.1720302\n",
            " 1.2264274 1.1078801 1.263725  1.2664342 1.1865743 1.2917569 1.3251425\n",
            " 1.1921109 1.2092464 1.2125512 1.334857  1.1989502 1.2080513 1.359245\n",
            " 1.3350174 1.1859639 1.4254118 1.2828411 1.1468177 1.0765707 1.1387622\n",
            " 1.3550678]\n",
            "Time taken for 1 epoch 8.137097597122192 sec\n",
            "\n",
            "Epoch 7 Batch 0 Loss [1.8066119  0.71224797 0.9301282  1.3029292  1.2863864  1.1710986\n",
            " 1.518428   0.9308207  1.0733175  1.5654852  1.21356    2.4464505\n",
            " 1.8397259  1.042947   1.2590234  0.560804   1.3923085  0.72293943\n",
            " 1.6559122  1.2083317  0.742119   0.5273542  1.6557727  1.0290588\n",
            " 1.5056462  1.0350018  0.9975261  1.6646261  2.046714   1.240976\n",
            " 1.6962447  0.37508723 1.0330814  1.2454     2.524476   1.3212717\n",
            " 1.3124311  1.8906543  0.9117635  0.79113555 1.0756749  0.6950623\n",
            " 1.6830658  1.3884757  1.4030206  2.2025511  1.1403862  0.91307425\n",
            " 0.548287   0.89728725 1.5565766  2.3962224  1.1095978  1.574533\n",
            " 0.79725164 0.7958482  1.7348264  0.331618   0.64165705 0.85046625\n",
            " 1.1442987  0.8830123  1.2281592  1.59934   ]\n",
            "Epoch 7 Loss [1.0230792  1.1179445  1.173074   1.1992533  1.130281   1.0854927\n",
            " 1.1115645  0.9964927  1.359765   1.245483   1.093926   1.0830626\n",
            " 1.108582   1.0289736  1.1714797  1.2772633  1.1014037  1.0001795\n",
            " 1.1828171  1.0849537  1.0605063  1.248972   1.0966163  1.09822\n",
            " 1.1331916  1.1711581  1.1111408  1.1490455  1.0907669  1.0683866\n",
            " 1.1469642  1.2463204  1.1085424  1.1868188  1.2013623  1.0684334\n",
            " 1.1883941  0.99613166 1.1862864  1.2340717  1.1357689  1.2365112\n",
            " 1.2524686  1.139712   1.0284355  1.241526   1.1104457  1.2024175\n",
            " 1.0721884  1.1620429  1.2351375  1.3154092  1.2079176  1.1597357\n",
            " 1.1063894  1.1204741  1.1463424  1.1005527  1.2183099  1.14841\n",
            " 1.1787497  1.0560625  1.1507798  1.033414  ]\n",
            "Time taken for 1 epoch 7.827229738235474 sec\n",
            "\n",
            "Epoch 8 Batch 0 Loss [1.1339579  1.8008946  0.75328004 0.4414922  0.7440207  0.6853788\n",
            " 0.977824   1.9137194  0.3210456  1.3479385  1.2606505  1.1359901\n",
            " 0.7276607  1.3878171  1.091251   1.0574912  0.32436255 1.2273724\n",
            " 0.9780969  0.7965138  0.612103   0.91649836 0.73258203 0.9982146\n",
            " 0.75933206 1.6244533  1.8588806  0.96706635 1.053277   0.7998863\n",
            " 1.6080629  1.2091149  1.0330839  1.4428203  1.2028303  0.6955619\n",
            " 0.528053   1.5549151  1.4804891  0.9216608  0.40987027 1.0109546\n",
            " 0.6938564  0.90947545 1.19165    0.9312736  1.0317043  0.5945487\n",
            " 1.1318318  1.0299695  1.0071143  1.7269917  1.0627083  0.9903684\n",
            " 0.6744936  1.1854972  0.7418082  1.3013332  1.1061975  0.35142383\n",
            " 0.5513975  0.50925785 0.4478295  0.88382107]\n",
            "Epoch 8 Loss [1.2455319  1.0567939  1.0253702  1.0263176  1.0275491  1.3097832\n",
            " 1.0275091  1.0366566  1.203115   1.1576221  1.0208422  1.0862522\n",
            " 1.0426726  1.0493298  1.0785367  1.186242   0.9561561  0.9864855\n",
            " 1.0768992  1.1210854  1.0157081  1.0273668  0.9296789  1.1495568\n",
            " 1.1172493  1.0509663  1.1686054  1.0165762  1.0927665  1.0458852\n",
            " 1.0809098  1.0893997  0.9875893  1.0928944  1.0671126  0.9676397\n",
            " 1.0987542  0.99133426 1.2435889  1.1164521  0.9880261  0.94672817\n",
            " 1.0671983  0.9931243  1.2373998  1.0586842  1.166739   0.9944247\n",
            " 1.0539746  1.0414501  1.0055099  1.1048713  1.2556406  1.1059775\n",
            " 0.9782397  1.1037905  1.0280219  1.2860057  1.2021894  1.156016\n",
            " 1.079741   0.97404915 1.0340354  1.0818148 ]\n",
            "Time taken for 1 epoch 8.252425909042358 sec\n",
            "\n",
            "Epoch 9 Batch 0 Loss [1.5116323  0.73580253 1.1702802  1.2508479  0.65754205 0.6256557\n",
            " 0.84442514 1.5116318  2.0203128  0.37827262 0.5938393  0.9616439\n",
            " 1.3460901  0.38383317 0.54186356 0.41319463 1.6887145  1.4434782\n",
            " 0.9620777  3.0611138  0.88179964 0.8803488  1.0269169  0.6928115\n",
            " 0.62479484 0.6762837  1.0711392  0.9949635  1.1954254  1.4883083\n",
            " 0.7572897  1.3826573  1.4209073  1.5974121  0.325183   0.52637064\n",
            " 0.8604424  1.4499627  1.5475879  1.3341025  0.8343998  0.37827456\n",
            " 0.9241351  0.79779685 1.0729773  1.1042624  1.4820359  0.79099107\n",
            " 0.42582795 1.7218547  0.65157586 0.17892589 1.0713251  0.8058061\n",
            " 0.76094633 0.61886066 1.7365232  0.19430707 0.5708349  0.8950557\n",
            " 0.77763397 0.55709565 0.8903972  2.1413655 ]\n",
            "Epoch 9 Loss [0.9574446  0.9681794  0.9604228  0.94228035 0.95778805 1.1629924\n",
            " 1.058353   1.0210383  1.0386198  0.94495416 1.010927   1.1430081\n",
            " 0.9439061  0.8596884  1.0875651  0.9987529  1.0284157  1.0260563\n",
            " 1.0906311  1.271418   1.0400449  0.859227   1.057079   0.97034615\n",
            " 1.0070599  1.038664   0.84667397 1.03796    0.89042544 1.0446148\n",
            " 1.0286833  0.9591394  1.0133818  1.1101602  1.0301841  1.0256957\n",
            " 0.96224564 0.8133821  0.9557273  1.0301988  1.0829663  1.1298604\n",
            " 1.029348   1.0720049  0.9600074  0.94528645 0.97522914 0.9914345\n",
            " 0.9926088  1.007676   0.9514513  1.1044275  1.0544866  0.9131219\n",
            " 0.94903564 0.9833592  1.0701824  1.0690508  1.05211    1.0968397\n",
            " 1.0404516  0.9132881  0.98044    1.2583427 ]\n",
            "Time taken for 1 epoch 7.937291860580444 sec\n",
            "\n",
            "Epoch 10 Batch 0 Loss [0.6870948  0.8569468  1.3822999  1.2645419  0.74626917 0.7854579\n",
            " 0.8560836  1.0010302  0.7867565  0.3420692  1.9211519  1.1550806\n",
            " 0.93377733 1.5626963  2.672051   0.39188766 0.8853447  1.53395\n",
            " 0.47902146 1.192168   0.52246505 0.67901784 1.9713124  0.6596091\n",
            " 1.613623   1.1399091  0.45916858 1.550957   1.1851333  2.103975\n",
            " 1.8824134  4.007224   1.1794837  0.97300667 0.7105859  0.8949697\n",
            " 0.3702004  1.164123   0.5186554  3.5409455  0.6414198  0.86864114\n",
            " 1.0687374  1.1253972  0.44777882 0.6490702  0.6916152  0.63389146\n",
            " 0.66227037 1.2321541  1.4639399  1.1613303  1.0340574  1.1385773\n",
            " 1.277523   0.7824466  0.8424154  1.284966   1.4071705  0.7635318\n",
            " 0.37130746 0.27156538 0.51068205 1.1417794 ]\n",
            "Epoch 10 Loss [0.9331075  0.89491683 0.9510291  1.068023   0.92280686 1.0193688\n",
            " 0.95572114 0.96596134 0.9958745  0.8578069  1.024034   0.9868702\n",
            " 0.98226696 1.0284007  0.9577496  1.0161837  1.0430255  0.9058428\n",
            " 0.9328029  0.844013   0.9103887  0.945055   0.97319233 0.9260932\n",
            " 1.0612916  1.057807   0.97359604 0.8377646  0.943061   0.8441406\n",
            " 0.96513873 1.0118923  0.9918675  0.97626317 1.008082   0.92671925\n",
            " 0.86478764 0.9157735  0.84296626 1.0552076  0.97141767 0.7897607\n",
            " 0.91690636 0.8924212  1.0041012  0.8578486  0.9739812  1.0277705\n",
            " 0.9575484  1.0146693  0.9324929  0.9743899  0.8671168  0.9740546\n",
            " 0.861091   0.99601674 0.8511741  0.84136516 1.021364   1.0549575\n",
            " 0.88058466 0.9963357  1.0940197  0.8988641 ]\n",
            "Time taken for 1 epoch 8.370858430862427 sec\n",
            "\n",
            "Epoch 11 Batch 0 Loss [0.8091785  1.8836197  0.92751914 0.9100988  0.4307924  0.8992948\n",
            " 0.4930839  1.2359256  0.6712615  0.57808447 0.8028743  0.8324575\n",
            " 0.6579874  1.2118806  0.8980734  0.82849514 1.0945345  0.7626483\n",
            " 0.6329165  0.6613646  1.5172185  0.8610094  0.6397423  0.9930807\n",
            " 0.6304938  0.7245431  1.8681921  1.0835412  1.4262335  0.48244688\n",
            " 0.6597003  0.76372266 0.5910211  1.649473   0.851105   0.9486871\n",
            " 0.6988337  1.0375546  0.21740259 1.0011665  0.7441463  0.5154424\n",
            " 0.78298634 0.9146003  0.56654847 0.61836547 0.8077411  0.99812895\n",
            " 0.9493337  1.8133837  1.0355501  3.7630668  0.7994799  0.8326437\n",
            " 1.0091987  0.4970566  0.9073022  0.23329084 1.3170502  0.9526009\n",
            " 1.8483256  0.2782034  1.3600508  0.36707208]\n",
            "Epoch 11 Loss [1.0138589  0.9440243  0.8931183  0.84821063 0.9211209  0.8402241\n",
            " 0.8614285  0.9096966  0.89491016 0.9274537  0.8677648  0.8949017\n",
            " 0.9023431  0.87331235 0.8758512  0.8884868  0.95525753 1.0175643\n",
            " 0.9878073  0.87642616 0.94502324 0.82887834 0.797267   0.86302257\n",
            " 0.8805517  0.8129413  0.8620138  0.88653696 0.8115028  0.88686156\n",
            " 0.92016494 0.85954404 0.8422688  0.84119046 0.9206021  1.0982289\n",
            " 0.920583   0.9390993  0.7880209  0.77909005 0.8692057  0.84481066\n",
            " 0.94402885 0.8598809  0.7627864  0.88532734 0.81674695 0.96148324\n",
            " 0.834054   0.8558413  1.0827489  1.0345064  0.89350647 0.81833714\n",
            " 0.8915238  0.81809145 0.8888305  0.9643664  0.9348104  0.974418\n",
            " 0.909697   0.82484543 0.9593168  0.9406287 ]\n",
            "Time taken for 1 epoch 8.027064561843872 sec\n",
            "\n",
            "Epoch 12 Batch 0 Loss [0.8071784  0.47389963 0.8580843  0.65465164 0.80250067 1.2262517\n",
            " 0.7242612  0.5954147  0.626913   0.74399734 0.5164279  2.1332743\n",
            " 0.44030005 0.6938891  1.0144111  0.73880506 0.6683297  0.5339247\n",
            " 0.9183892  0.47985175 1.139151   0.71531373 0.51284164 0.6229026\n",
            " 0.58527523 0.41193923 0.19282494 0.36430562 0.69360054 1.4029384\n",
            " 0.62288547 0.71014065 2.6607287  0.68860507 0.7593259  0.78792953\n",
            " 0.6367314  0.6011607  0.83410203 1.2769749  0.8322877  0.68586564\n",
            " 0.85559064 0.354339   0.86205894 1.3549223  1.0436621  0.39902928\n",
            " 0.9892913  0.85659796 0.4778503  0.39433184 0.4580192  0.3301213\n",
            " 1.2695172  0.65239805 0.6347967  0.83849096 0.878429   1.3062848\n",
            " 0.9580395  0.3965223  0.7260455  1.9438248 ]\n",
            "Epoch 12 Loss [0.8634887  0.9254443  0.86193794 0.78026193 0.83267564 0.8903333\n",
            " 0.93409604 0.8164121  0.9153876  0.8561529  0.72964936 0.821128\n",
            " 0.85666925 0.9150858  0.8018226  0.7601559  0.97235966 0.77279687\n",
            " 0.7305105  0.75119764 0.8787811  0.8604211  0.7902777  0.7295955\n",
            " 0.75936395 0.65786976 0.8585184  0.86763424 0.9770562  0.9754183\n",
            " 0.8273707  0.82289803 0.91591424 0.7775617  0.88883275 0.8849006\n",
            " 0.759242   0.802033   0.7961147  0.8833852  0.9831364  0.87421584\n",
            " 0.7954004  0.76643795 0.95714736 0.926624   0.86662805 0.8889968\n",
            " 0.95685387 0.88807774 0.9137655  0.92454094 0.9236667  0.8158374\n",
            " 0.8187736  0.7207761  0.7916979  0.7694798  0.75681144 0.80107015\n",
            " 0.7548117  0.72480166 0.76839405 0.822706  ]\n",
            "Time taken for 1 epoch 8.488090515136719 sec\n",
            "\n",
            "Epoch 13 Batch 0 Loss [0.43600762 0.8712698  0.86265695 1.0139958  0.6312481  0.54056346\n",
            " 0.57930046 0.84330636 1.3961587  0.675227   1.0352491  0.56111866\n",
            " 1.1052605  0.5823366  0.54079765 1.3844756  0.4309635  0.79183143\n",
            " 1.4450747  0.7916373  0.8375638  0.8845929  1.0973253  0.98919517\n",
            " 0.3213802  0.785461   0.73802906 0.6578686  0.7353084  0.4195898\n",
            " 0.9736507  0.84718084 0.38550517 0.7540277  1.3981589  0.39899763\n",
            " 1.0407269  0.6732266  1.169436   0.19225253 0.42015588 0.9608529\n",
            " 0.46756974 1.3688436  0.71695566 0.91721344 0.94245327 0.97516185\n",
            " 0.55158263 0.55479825 1.2004157  1.3666565  1.2994337  0.5504308\n",
            " 0.78247875 0.9027648  0.93783385 0.6612138  0.90016776 0.4465024\n",
            " 0.6362763  0.49752864 0.71319765 1.5307273 ]\n",
            "Epoch 13 Loss [0.75573146 0.69627434 0.77253747 0.79170394 0.86093605 0.8208797\n",
            " 0.8156798  0.6767599  0.7492818  0.9161965  0.8207305  0.894489\n",
            " 0.7703101  0.9173818  0.77743673 0.64589906 0.6930659  0.73963976\n",
            " 0.7355548  0.84828645 0.7141812  0.7087573  0.7098604  0.7936171\n",
            " 0.67494243 0.7213789  0.7923176  0.79929924 0.8052351  0.7260697\n",
            " 0.84855413 0.7238777  0.7427583  0.8235684  0.71014285 0.8066702\n",
            " 0.8170611  0.9181667  0.8401962  0.7761959  0.8215612  0.7229188\n",
            " 0.7979339  0.8091796  0.76988727 0.75554657 0.8031086  0.80173486\n",
            " 0.7372381  0.80279565 0.8479787  0.77804035 0.78058445 0.7320621\n",
            " 0.76414824 0.78021944 0.76789814 0.82851833 0.73812675 0.737496\n",
            " 0.7355137  0.7246951  0.82095397 0.8044401 ]\n",
            "Time taken for 1 epoch 8.17240834236145 sec\n",
            "\n",
            "Epoch 14 Batch 0 Loss [1.0207148  0.23816898 0.4756302  0.34151003 0.41560388 0.6032616\n",
            " 0.31541646 0.2539335  0.37814167 1.1013302  1.2368331  1.1504655\n",
            " 0.68523115 0.6101185  0.71152127 0.49885026 0.66530955 0.3129927\n",
            " 0.7194073  0.42530957 0.5696395  0.57552767 0.8023117  0.39780986\n",
            " 0.52026916 0.7529712  1.1320578  0.56536    0.49693707 0.3156501\n",
            " 0.31201145 0.36057633 0.9751854  0.7381268  0.83583343 0.48721486\n",
            " 0.58257693 0.6748365  0.400542   0.36022824 0.883959   0.97549176\n",
            " 0.64954484 0.49298602 0.93151146 2.1033657  0.69066215 0.5113123\n",
            " 0.2470401  1.2070575  0.55555636 0.48739794 0.34220475 1.7293127\n",
            " 0.7675355  0.42106324 1.0692796  0.42737842 1.4253706  0.5990789\n",
            " 0.7941603  0.33767098 0.46087962 0.7909896 ]\n",
            "Epoch 14 Loss [0.6515883  0.7891559  0.89492387 0.6643697  0.69977355 0.63746554\n",
            " 0.8062778  0.6639399  0.7084314  0.74921095 0.7280331  0.75665206\n",
            " 0.6902077  0.6375783  0.716193   0.73460674 0.65463907 0.6627504\n",
            " 0.7019125  0.6879897  0.6789286  0.7192255  0.81041443 0.7223118\n",
            " 0.8534075  0.77073205 0.8121949  0.6727722  0.7395265  0.71768445\n",
            " 0.7158286  0.7282899  0.7297196  0.70946574 0.71625865 0.6479142\n",
            " 0.7198818  0.65704644 0.71006036 0.67554605 0.71320623 0.79423666\n",
            " 0.5972445  0.71112347 0.6837705  0.74379545 0.72505134 0.7217641\n",
            " 0.6912086  0.75669646 0.6932941  0.72173893 0.7340871  0.7569392\n",
            " 0.63466656 0.67039156 0.6442291  0.7091619  0.8002676  0.7400105\n",
            " 0.74243116 0.7643364  0.7143031  0.71150947]\n",
            "Time taken for 1 epoch 8.541760206222534 sec\n",
            "\n",
            "Epoch 15 Batch 0 Loss [0.5307601  1.9409827  0.46159172 0.35058877 0.5257325  0.4852618\n",
            " 0.40956458 0.77711433 0.22157733 0.46333542 0.3253362  0.9047769\n",
            " 0.55572104 0.8491893  0.6495336  0.205132   1.1867613  0.36305106\n",
            " 0.93710184 0.49311244 0.49560997 0.609838   0.80252445 0.56093895\n",
            " 0.45939943 0.73451996 0.62355936 0.26970696 0.28515232 0.32436463\n",
            " 0.80987024 0.32329297 1.1887631  0.94947803 0.7005819  0.1636294\n",
            " 0.28245142 0.26899266 0.355504   0.72421134 1.1264855  0.6519626\n",
            " 0.6090976  1.0420358  0.44833058 0.5092887  0.46333846 0.28405342\n",
            " 0.54620606 0.8660931  0.70434076 0.993265   0.31137004 1.1351477\n",
            " 0.3975629  0.7442702  0.32942036 0.21292606 0.67742157 0.48691994\n",
            " 0.5912215  0.5397227  0.6343683  0.47813132]\n",
            "Epoch 15 Loss [0.584738   0.7851486  0.6201632  0.54924726 0.68254113 0.67526424\n",
            " 0.62529016 0.70841116 0.68115413 0.6744133  0.7277276  0.62888277\n",
            " 0.72572714 0.6426072  0.8549242  0.70509267 0.7175596  0.6891838\n",
            " 0.5993574  0.63203627 0.6642593  0.5856141  0.6597985  0.5812911\n",
            " 0.5478338  0.6703754  0.5422032  0.6343302  0.59440315 0.78777844\n",
            " 0.69934344 0.614201   0.6564707  0.7142656  0.5956069  0.79539955\n",
            " 0.5987984  0.62823987 0.71372545 0.7011634  0.7148     0.58410233\n",
            " 0.6731185  0.630133   0.6376492  0.74574834 0.6211586  0.6872976\n",
            " 0.64470047 0.7311743  0.66561854 0.79739463 0.720638   0.5810263\n",
            " 0.5769637  0.7036049  0.6227316  0.70924914 0.7292701  0.6919991\n",
            " 0.65263134 0.7040109  0.73084944 0.6563857 ]\n",
            "Time taken for 1 epoch 8.092419385910034 sec\n",
            "\n",
            "Epoch 16 Batch 0 Loss [0.3046071  1.0276164  0.41236234 0.49941275 0.5614079  0.83233327\n",
            " 0.8457161  0.6279867  0.29302466 0.7968746  0.3678338  0.6520811\n",
            " 1.2030393  0.46837872 0.22431879 1.1816607  0.5121748  0.67042804\n",
            " 0.23867384 0.67569673 0.37172702 0.13791731 0.64634943 0.52735955\n",
            " 0.22772644 0.1951185  0.40557244 0.23492445 0.3045459  0.2791291\n",
            " 0.30385995 0.65560126 0.25955626 0.79394716 0.521878   0.4377857\n",
            " 0.46496332 0.3542756  0.45832083 1.2811643  0.5165055  0.43826893\n",
            " 0.5245375  0.72993153 0.14283676 0.37173498 0.51426977 0.5591919\n",
            " 0.39991108 0.35592988 0.6394106  1.0695138  0.5515273  0.61249477\n",
            " 0.3381717  0.37005615 0.41417536 1.5252407  0.21024266 0.42854494\n",
            " 0.9947003  0.46888712 0.3394369  0.6678116 ]\n",
            "Epoch 16 Loss [0.71383125 0.67559814 0.5032501  0.75768214 0.5996958  0.6608439\n",
            " 0.6601095  0.53826207 0.66609675 0.59409356 0.57400435 0.6014681\n",
            " 0.5888101  0.5629295  0.613688   0.71975917 0.6010239  0.5971883\n",
            " 0.5111568  0.5917865  0.5251192  0.66245866 0.6374743  0.55507207\n",
            " 0.6214986  0.67289454 0.60253143 0.67611265 0.72159064 0.62244916\n",
            " 0.5813636  0.60719335 0.5674851  0.5669371  0.55288225 0.6432669\n",
            " 0.6390297  0.62696314 0.5763398  0.547349   0.6271428  0.58308893\n",
            " 0.5763593  0.6555016  0.62351394 0.5813022  0.532392   0.7245064\n",
            " 0.6034965  0.56470424 0.57128274 0.6328613  0.66083735 0.6276134\n",
            " 0.5283002  0.558798   0.58050084 0.69389224 0.65996706 0.59647256\n",
            " 0.69507563 0.6987184  0.54802537 0.5057427 ]\n",
            "Time taken for 1 epoch 8.412712812423706 sec\n",
            "\n",
            "Epoch 17 Batch 0 Loss [0.4931659  0.77420187 0.15733454 1.0217799  0.22595498 0.19732703\n",
            " 0.67046785 0.29141116 0.38920942 0.93916833 0.4674021  1.0993558\n",
            " 0.46402526 0.3789306  0.10408892 0.37804228 0.20537956 0.6222379\n",
            " 0.17315188 0.31087568 0.46640092 0.584002   0.29434872 0.5388345\n",
            " 0.46386358 0.46590135 0.23433985 0.9779993  0.58433366 0.21241203\n",
            " 0.7726496  0.21378307 0.7217527  0.37664342 0.35867763 1.1892397\n",
            " 0.16025397 0.6804127  0.2654652  0.4844496  0.51364493 0.3035233\n",
            " 0.2617094  0.98373914 1.0619597  0.38751444 0.7506368  0.34467435\n",
            " 0.82874566 0.2723217  0.41085073 0.49096712 0.4866141  0.5364208\n",
            " 0.8297151  0.471254   0.7346015  0.4141032  0.40220702 0.3761119\n",
            " 0.63687    0.48423287 0.2605132  0.22592674]\n",
            "Epoch 17 Loss [0.6388128  0.5114188  0.54715025 0.53426576 0.53322583 0.55352384\n",
            " 0.55889225 0.60273427 0.59582114 0.61298347 0.6047878  0.6738146\n",
            " 0.54577184 0.5644388  0.6405998  0.5372418  0.5722091  0.5794638\n",
            " 0.50712645 0.49671948 0.4842246  0.65050375 0.55776495 0.5661678\n",
            " 0.5023953  0.548374   0.60256    0.5880764  0.55259883 0.57504374\n",
            " 0.5826863  0.61278397 0.64131707 0.5389722  0.5290029  0.6174161\n",
            " 0.50934005 0.48408684 0.6094513  0.4425243  0.5289549  0.4525361\n",
            " 0.5260982  0.7431179  0.66284823 0.48747894 0.45427704 0.55919945\n",
            " 0.532347   0.49383122 0.5111523  0.6282683  0.62053347 0.56119937\n",
            " 0.5771504  0.53641135 0.5736387  0.64374423 0.5151966  0.5571218\n",
            " 0.49993837 0.5007927  0.54851514 0.5774024 ]\n",
            "Time taken for 1 epoch 8.038251399993896 sec\n",
            "\n",
            "Epoch 18 Batch 0 Loss [0.2384559  0.14994925 0.5315858  0.709004   0.61934996 0.7854911\n",
            " 0.39639768 0.89912903 0.15065603 0.7267571  0.66515726 0.10754103\n",
            " 0.498895   0.7363097  0.4694917  0.28389055 0.7771434  0.49163234\n",
            " 0.6028684  0.2470683  0.43585682 0.9442164  0.23267446 0.22519624\n",
            " 0.31821954 0.63903075 0.11019859 0.71160436 0.4932441  0.45292616\n",
            " 0.22660457 0.31795287 0.37098503 0.42805836 0.08193082 0.5101114\n",
            " 0.72911555 1.0764142  0.4544057  0.2640021  0.9819402  1.0661619\n",
            " 0.98624974 1.1185466  0.49979246 0.5359192  0.47064212 0.13357167\n",
            " 0.17459396 0.5064699  0.46852183 0.5008766  0.48208526 0.19637886\n",
            " 0.24181703 0.8075297  0.47880498 0.21652906 0.59357655 0.38796952\n",
            " 1.1071656  0.27334565 1.0550257  0.29888153]\n",
            "Epoch 18 Loss [0.52105325 0.4200358  0.52207017 0.5508721  0.4930581  0.51418453\n",
            " 0.48455805 0.53619987 0.50218    0.493045   0.45061848 0.46678406\n",
            " 0.55750644 0.52448237 0.43930507 0.58019143 0.53655493 0.494125\n",
            " 0.46341187 0.5123638  0.5179786  0.52140653 0.47199473 0.48195612\n",
            " 0.5009977  0.5570981  0.45384407 0.5520108  0.5492336  0.6383613\n",
            " 0.4829253  0.48565018 0.45993513 0.4978011  0.45620394 0.48057714\n",
            " 0.4924631  0.5756869  0.44763675 0.5327747  0.53547734 0.51156336\n",
            " 0.5131197  0.5223343  0.49770033 0.5907609  0.52653766 0.51892006\n",
            " 0.46830294 0.5189372  0.45900944 0.5165988  0.5562789  0.48996258\n",
            " 0.5102082  0.51988715 0.5561737  0.5271843  0.5082624  0.47465774\n",
            " 0.5581808  0.5430957  0.6023891  0.5647853 ]\n",
            "Time taken for 1 epoch 8.41007399559021 sec\n",
            "\n",
            "Epoch 19 Batch 0 Loss [0.0682852  0.47819448 0.2906904  0.58168656 1.450631   0.23256126\n",
            " 0.17484248 0.72052276 0.1597791  0.3040553  0.5468403  0.3412658\n",
            " 0.8921475  0.19377592 0.35712698 0.31468147 0.6627974  0.29881296\n",
            " 0.2228295  0.61756635 0.50659806 0.17080908 0.35930225 0.9303631\n",
            " 0.741798   0.72689277 0.38012156 0.35242814 0.50071007 0.14000992\n",
            " 0.14719239 0.16524617 0.5091737  0.21375145 0.1362563  0.7125799\n",
            " 0.63740104 0.55544466 0.47458583 0.70733815 0.59153926 0.2917689\n",
            " 0.3707943  0.6589363  0.21420303 0.3499398  0.181637   0.32379967\n",
            " 0.23897488 0.521093   0.2934675  0.3409258  0.7996911  0.4073576\n",
            " 0.48995665 0.3254144  0.552775   0.09641211 0.2825028  0.209322\n",
            " 0.69646966 0.86924046 0.05765063 0.3439218 ]\n",
            "Epoch 19 Loss [0.43837252 0.4966365  0.44964498 0.3830533  0.5259506  0.41996595\n",
            " 0.44322035 0.52342    0.44042253 0.42346928 0.43190444 0.3910411\n",
            " 0.46499115 0.43682092 0.47362095 0.49992174 0.434421   0.46127558\n",
            " 0.4519908  0.4743512  0.52720803 0.5300716  0.38421354 0.47742403\n",
            " 0.5107262  0.55370086 0.41321927 0.568255   0.45157242 0.44895378\n",
            " 0.4706572  0.42562476 0.436952   0.47041097 0.47685686 0.48425293\n",
            " 0.46144778 0.4736346  0.4118051  0.48451418 0.49382463 0.49214157\n",
            " 0.46439445 0.48092243 0.4720168  0.4010104  0.50264126 0.5131363\n",
            " 0.511711   0.5069685  0.4744324  0.40074843 0.48475063 0.52084154\n",
            " 0.46618688 0.42143574 0.4487301  0.547271   0.42488524 0.4283953\n",
            " 0.43273744 0.5401943  0.49332884 0.4381798 ]\n",
            "Time taken for 1 epoch 8.025684595108032 sec\n",
            "\n",
            "Epoch 20 Batch 0 Loss [0.45487452 0.23457713 0.26682425 0.1894911  0.31534606 0.14215976\n",
            " 0.4798445  0.338734   0.5300618  0.29456586 0.45092013 0.7418456\n",
            " 0.43517914 0.32385162 0.29601938 0.2382335  0.31475988 0.3686457\n",
            " 0.24163102 0.3734719  0.33062014 0.43770802 0.35434258 0.1303503\n",
            " 0.85194767 0.07397185 0.09706844 0.27359012 0.2821464  0.9128799\n",
            " 0.771937   0.18307522 0.8964157  0.2615401  0.42167312 0.51826173\n",
            " 0.2563365  0.3492065  0.422852   0.5014789  0.4518471  0.27500844\n",
            " 0.28683624 0.21372387 0.16172771 0.7219262  0.36518347 0.07853778\n",
            " 0.29642305 0.848178   0.6339805  0.45253608 0.4107432  1.1738765\n",
            " 0.6085568  0.0827654  0.51838183 0.2841129  0.48632675 0.5926382\n",
            " 0.6167823  0.5170186  0.17076671 0.32243767]\n",
            "Epoch 20 Loss [0.46400568 0.36722514 0.3854666  0.39032272 0.51293    0.4541286\n",
            " 0.39984637 0.45973963 0.42196772 0.35395426 0.46811518 0.41943687\n",
            " 0.518047   0.41978833 0.40573895 0.3694507  0.4657084  0.3949698\n",
            " 0.39324373 0.4454803  0.40855724 0.3659833  0.45312896 0.43596864\n",
            " 0.43120962 0.3568229  0.40908167 0.44691065 0.45993504 0.4485272\n",
            " 0.38519463 0.33651716 0.49722904 0.42971352 0.39699647 0.40436846\n",
            " 0.35741925 0.504658   0.35252473 0.40626147 0.49904197 0.49685547\n",
            " 0.4033342  0.4993602  0.43001768 0.399518   0.3986111  0.44629776\n",
            " 0.36096388 0.49698198 0.46488035 0.38509768 0.424602   0.47377825\n",
            " 0.48483297 0.45356634 0.41201934 0.43579423 0.43010548 0.39658454\n",
            " 0.45785633 0.39718446 0.36703384 0.36099672]\n",
            "Time taken for 1 epoch 8.398672103881836 sec\n",
            "\n",
            "Epoch 21 Batch 0 Loss [0.19277059 0.13306403 0.4950962  0.31514245 0.27474988 0.215614\n",
            " 1.0871786  0.21031581 0.27085102 0.16777247 0.35806906 0.17708623\n",
            " 0.16272257 0.60314167 0.5817763  0.1291896  0.15526265 0.4301431\n",
            " 0.14224125 0.38951927 0.27175605 0.46698594 0.15882729 0.24277224\n",
            " 0.22302641 0.09866428 0.42181376 0.20394117 0.22427967 0.26868927\n",
            " 0.758505   0.16284293 0.25926033 0.3666723  0.1772904  0.38597417\n",
            " 0.27733743 0.43584323 0.2462385  0.3501397  0.16291441 0.49631262\n",
            " 0.15908903 0.20904769 0.30830437 0.55396825 0.1491121  0.50594074\n",
            " 0.6822285  0.42580807 0.48458463 0.37675753 0.32418382 0.15441997\n",
            " 0.42146942 0.6104003  0.39581358 0.2626001  0.27583706 0.26975977\n",
            " 0.16007172 0.1093817  0.458116   0.37307352]\n",
            "Epoch 21 Loss [0.39070487 0.34577918 0.38962597 0.3417746  0.37395158 0.41604248\n",
            " 0.41658008 0.3897232  0.35664532 0.38569516 0.4152789  0.36226553\n",
            " 0.39911988 0.3976785  0.33258542 0.36442006 0.43190655 0.32232174\n",
            " 0.3406394  0.37638012 0.41365415 0.331641   0.35420287 0.3370888\n",
            " 0.43030295 0.36292377 0.40794867 0.33187318 0.32832804 0.31989858\n",
            " 0.41489232 0.3603724  0.37933165 0.44974238 0.40569675 0.39893302\n",
            " 0.4265306  0.40288445 0.3414927  0.39786428 0.45512247 0.42943102\n",
            " 0.34882367 0.37631357 0.38781536 0.37479532 0.36281633 0.33834055\n",
            " 0.36710274 0.36114293 0.37236044 0.37615725 0.41579568 0.40218458\n",
            " 0.33157855 0.3694615  0.33110932 0.3261823  0.40561572 0.4436262\n",
            " 0.33402035 0.394692   0.43157452 0.34118357]\n",
            "Time taken for 1 epoch 8.060224771499634 sec\n",
            "\n",
            "Epoch 22 Batch 0 Loss [0.18585327 0.13122281 0.3964793  0.3793205  0.13317493 0.6262286\n",
            " 0.10184646 0.18759112 0.27696568 0.3494168  0.46487683 0.37645826\n",
            " 0.38649538 0.17649575 0.14825778 0.08416218 0.25755244 0.12874186\n",
            " 0.67329097 0.28708917 0.07538203 0.2182614  0.7043049  0.22719413\n",
            " 0.7463483  0.07334303 0.20589617 0.4249641  0.584813   0.23342524\n",
            " 0.23204245 0.23082842 0.11988121 0.27535412 0.1647955  0.19313918\n",
            " 0.09305868 0.3637564  0.11247879 0.4778184  0.39128238 0.13505618\n",
            " 0.39783397 0.24451442 0.3949566  0.10877936 0.13498044 0.35656393\n",
            " 0.11941234 0.3680164  0.1054683  0.06979682 0.16760191 0.22267908\n",
            " 0.21074167 0.32365718 0.41964716 0.37122515 0.14447819 0.08400468\n",
            " 0.431522   0.14958726 0.50733167 0.15270266]\n",
            "Epoch 22 Loss [0.43560657 0.3703117  0.38200805 0.34849694 0.31136358 0.34687883\n",
            " 0.29129842 0.27565667 0.3122334  0.2818066  0.35588825 0.3964718\n",
            " 0.3542068  0.35011846 0.3674467  0.33520937 0.37010437 0.40202057\n",
            " 0.36789235 0.39540023 0.3438741  0.28756845 0.34360415 0.3646518\n",
            " 0.33233377 0.30785477 0.38524377 0.3080594  0.32433924 0.34155044\n",
            " 0.31697106 0.37275705 0.2786284  0.3061097  0.36411136 0.32788655\n",
            " 0.29443854 0.328451   0.29491904 0.28211105 0.3366421  0.3847511\n",
            " 0.33341318 0.35794678 0.3139118  0.31356594 0.40091223 0.3261239\n",
            " 0.3499812  0.34993154 0.39268807 0.3540477  0.3797526  0.34021044\n",
            " 0.41156277 0.33249685 0.3396323  0.3226605  0.3091908  0.272442\n",
            " 0.29472598 0.32959682 0.37754038 0.35946494]\n",
            "Time taken for 1 epoch 8.46855115890503 sec\n",
            "\n",
            "Epoch 23 Batch 0 Loss [0.83318573 0.1965077  0.38791263 0.58403707 0.21543157 0.19563456\n",
            " 0.40420106 0.4053911  0.06554308 0.12123087 0.244874   0.26276234\n",
            " 0.24812175 0.27223024 0.25909024 0.78069645 0.04038067 0.12603103\n",
            " 0.320413   0.3709568  0.46187258 0.4544932  0.2977116  0.24738094\n",
            " 0.14895524 0.18423715 0.1215717  0.3056039  0.11168358 0.26905486\n",
            " 0.27614883 0.36774102 0.07118309 0.31124744 0.74927115 0.19029777\n",
            " 0.11443565 0.49721676 0.19859047 0.09730817 0.11761252 0.1744344\n",
            " 0.35345912 1.2249172  0.05589736 0.19115242 0.1797351  0.33420742\n",
            " 0.06567024 0.4000352  0.18698445 0.2081041  0.1998489  0.29135692\n",
            " 0.5156068  0.7119396  0.08665344 0.34142804 0.54634124 0.24651825\n",
            " 0.09422009 0.3598531  0.21978962 0.21865973]\n",
            "Epoch 23 Loss [0.32406166 0.303072   0.31398192 0.3348533  0.2674496  0.3012385\n",
            " 0.26846325 0.32856616 0.23013854 0.32281494 0.29889968 0.29487494\n",
            " 0.3011087  0.26035523 0.2876167  0.3462827  0.30300972 0.3295387\n",
            " 0.33404595 0.2886661  0.3107004  0.28278023 0.32983544 0.32366192\n",
            " 0.29338712 0.31035188 0.25261146 0.3035271  0.31853545 0.3170461\n",
            " 0.349385   0.24826545 0.35608935 0.34265777 0.3206536  0.25402987\n",
            " 0.29707065 0.37901923 0.3182503  0.25120822 0.32602298 0.24560864\n",
            " 0.23110154 0.36098593 0.31793678 0.28101477 0.28692818 0.32935998\n",
            " 0.2544695  0.29609787 0.3414477  0.28417772 0.30853808 0.26417384\n",
            " 0.34524122 0.29205215 0.39039287 0.296457   0.29790735 0.3144339\n",
            " 0.27472407 0.32566687 0.32347208 0.34886655]\n",
            "Time taken for 1 epoch 8.09061861038208 sec\n",
            "\n",
            "Epoch 24 Batch 0 Loss [0.32489967 0.15730895 0.3265951  0.21649657 0.25025967 0.36462\n",
            " 0.307382   0.1770511  0.18444128 0.07486092 0.03592475 0.3280134\n",
            " 0.15551965 0.20327374 0.50824934 0.32114056 0.08901111 0.24858281\n",
            " 0.30285022 1.0335366  0.20315517 0.1433269  0.29581496 0.0241949\n",
            " 0.23025963 0.49213693 0.21184073 0.22678688 0.05820255 0.05773588\n",
            " 0.35818487 0.20973611 0.3332059  0.14337625 0.16073216 0.36798683\n",
            " 0.07787874 0.14062533 0.14929806 0.20116681 0.25458276 0.12340146\n",
            " 0.16086087 0.1710756  0.88179404 0.15534343 0.90306723 0.2214529\n",
            " 0.37675548 0.17649776 0.59808904 0.19251502 0.23047023 0.13506995\n",
            " 0.40414268 0.0698529  0.4969752  0.36159396 0.35638157 0.07280603\n",
            " 0.44011617 0.14232194 0.6242485  0.1725662 ]\n",
            "Epoch 24 Loss [0.28876016 0.27205637 0.3237299  0.25097054 0.2763708  0.31210095\n",
            " 0.30636242 0.25653884 0.30223814 0.28364536 0.21621895 0.26602682\n",
            " 0.30114886 0.30915615 0.32362968 0.23481196 0.23891169 0.23501608\n",
            " 0.23831558 0.28396505 0.24360803 0.2766937  0.24335808 0.24959612\n",
            " 0.23141034 0.21805435 0.24882936 0.28114116 0.28068897 0.30791256\n",
            " 0.23790328 0.2722418  0.26097667 0.22602195 0.21904571 0.27920943\n",
            " 0.30939788 0.28938353 0.24678543 0.24205177 0.24158904 0.28080988\n",
            " 0.27100253 0.2896716  0.25918552 0.25501335 0.25841698 0.30024374\n",
            " 0.25470296 0.22867121 0.23833394 0.25079912 0.26649368 0.30194548\n",
            " 0.2627335  0.21356405 0.32578215 0.245768   0.29140908 0.28585836\n",
            " 0.27437106 0.2796065  0.29223981 0.24766643]\n",
            "Time taken for 1 epoch 8.47199034690857 sec\n",
            "\n",
            "Epoch 25 Batch 0 Loss [0.4670704  0.4835956  0.2791693  0.12976605 0.14613232 0.16482046\n",
            " 0.47028413 0.2063011  0.02475037 0.10687345 0.24712901 0.20812248\n",
            " 0.09128602 0.07582656 0.1533438  0.07999612 0.05784409 0.34177867\n",
            " 0.06109012 0.11381868 0.06253173 0.02613036 0.21643719 0.45756036\n",
            " 0.34853894 0.22327167 0.22115777 0.02928111 0.17763753 0.43434072\n",
            " 0.09878666 0.1164651  0.22644597 0.30202293 0.11027041 0.23736417\n",
            " 0.06530244 0.20186539 0.08918682 0.35251492 1.3031427  0.15880662\n",
            " 0.27375305 0.29537928 0.17544845 0.3169709  0.16851932 0.53529805\n",
            " 0.20769966 0.42714602 0.08232595 0.14508194 0.1339012  0.21700129\n",
            " 0.1364035  0.03731911 0.11892283 0.01640242 0.4429985  0.0679059\n",
            " 0.4328057  0.05906235 0.27187353 0.1702796 ]\n",
            "Epoch 25 Loss [0.23066515 0.20268062 0.23416908 0.2638802  0.26927865 0.20881693\n",
            " 0.24703921 0.21590097 0.21161547 0.21654074 0.23084259 0.22548045\n",
            " 0.24827558 0.24448827 0.24848665 0.1894676  0.22557814 0.21805666\n",
            " 0.2231918  0.20843476 0.19281764 0.22761437 0.21572171 0.22356105\n",
            " 0.2560417  0.2348904  0.23184991 0.2440425  0.22393706 0.22157708\n",
            " 0.19706468 0.17574997 0.27500606 0.19689465 0.22742939 0.22607973\n",
            " 0.27047315 0.25199547 0.19677895 0.22175653 0.26204368 0.21650144\n",
            " 0.2514205  0.2504636  0.20822991 0.19941862 0.216642   0.19719017\n",
            " 0.21866728 0.30041435 0.16877426 0.2536123  0.25839007 0.20267728\n",
            " 0.2758413  0.17203487 0.23349339 0.3104244  0.20038517 0.24230787\n",
            " 0.2737492  0.20082635 0.22435766 0.25108624]\n",
            "Time taken for 1 epoch 8.07524585723877 sec\n",
            "\n",
            "Epoch 26 Batch 0 Loss [0.28872    0.07142875 0.44490084 0.21342354 0.06040782 0.1934625\n",
            " 0.23191777 0.10949408 0.24218352 0.09836541 0.21231665 0.03519686\n",
            " 0.18472268 0.35273525 0.03316168 0.09913428 0.05337163 0.08430229\n",
            " 0.1289055  0.06345906 0.17963716 0.11101515 0.05388761 0.18233015\n",
            " 0.6205307  0.12666066 0.02897324 0.23437838 0.13189723 0.05271025\n",
            " 0.7124468  0.02550336 0.04370216 0.06741009 0.13633373 0.2387788\n",
            " 0.0964556  0.18887098 0.07008363 0.07931454 0.21021567 0.07412773\n",
            " 0.25989318 0.6599262  0.03301031 0.38774437 0.11310211 0.15852632\n",
            " 0.22271438 0.0303207  0.05800186 0.17085046 0.0305561  0.18495284\n",
            " 0.39665928 0.3678611  0.49493518 0.41399455 0.17179954 0.19025806\n",
            " 0.205584   0.2245759  0.1757698  0.07758731]\n",
            "Epoch 26 Loss [0.20721236 0.22777289 0.19980474 0.19834259 0.20582259 0.2020493\n",
            " 0.18979476 0.19601795 0.17899151 0.1630091  0.18938547 0.18474309\n",
            " 0.22296518 0.2443383  0.14370409 0.18882024 0.20971316 0.16178085\n",
            " 0.20695695 0.22630304 0.22358306 0.17885332 0.16787617 0.20701833\n",
            " 0.23091957 0.18701643 0.16524814 0.20692377 0.18047564 0.22991045\n",
            " 0.25093585 0.17801166 0.21673729 0.15870517 0.19822422 0.17496063\n",
            " 0.18162516 0.18267669 0.22585495 0.24267316 0.20512472 0.2228747\n",
            " 0.24074316 0.19132203 0.17818406 0.1920899  0.19526808 0.22249538\n",
            " 0.18874998 0.15831237 0.22532757 0.17995836 0.18834783 0.19049278\n",
            " 0.22223717 0.19095075 0.21999611 0.25111735 0.18111868 0.18373965\n",
            " 0.18254168 0.212354   0.20379081 0.17792916]\n",
            "Time taken for 1 epoch 8.421905994415283 sec\n",
            "\n",
            "Epoch 27 Batch 0 Loss [0.06312366 0.14878415 0.20584653 0.157507   0.15081093 0.10183761\n",
            " 0.11812185 0.09053477 0.06070804 0.05155302 0.6897053  0.24982367\n",
            " 0.09834956 0.12960362 0.17988278 0.09241456 0.03225436 0.4586925\n",
            " 0.14019273 0.24211526 0.14279477 0.08117829 0.07934321 0.10734296\n",
            " 0.21023579 0.1152569  0.7290703  0.0661163  0.62885505 0.26703066\n",
            " 0.21427521 0.07118539 0.3312326  0.4785808  0.49407262 0.03747036\n",
            " 0.11382981 0.02148126 0.23794733 0.09439388 0.02528036 0.03514446\n",
            " 0.14562032 0.15868741 0.0755542  0.13766873 0.06652214 0.17224595\n",
            " 0.15444586 0.02272196 0.09876127 0.18897083 0.15480784 0.11444101\n",
            " 0.01822006 0.28616348 0.16957329 0.1034724  0.44332102 0.02815795\n",
            " 0.0284513  0.19408534 0.1430269  0.10127337]\n",
            "Epoch 27 Loss [0.13910742 0.1488757  0.19864504 0.20802933 0.19647026 0.20451204\n",
            " 0.19671288 0.16520973 0.16143799 0.1593506  0.18676385 0.1555834\n",
            " 0.1881982  0.15124898 0.19535634 0.14541513 0.17809062 0.19477883\n",
            " 0.13987033 0.16538762 0.21057993 0.15177856 0.14716746 0.15749516\n",
            " 0.1783538  0.13027619 0.16495559 0.18642327 0.16560978 0.16183583\n",
            " 0.15835313 0.14182381 0.21097344 0.15301786 0.19624978 0.16348349\n",
            " 0.16823712 0.16800433 0.17999487 0.1725642  0.20778857 0.19040567\n",
            " 0.20530918 0.16101554 0.11398426 0.15050395 0.132952   0.17668717\n",
            " 0.17596741 0.15177387 0.20038356 0.14430788 0.14819583 0.15019403\n",
            " 0.20408474 0.14792871 0.19340883 0.1633397  0.14304297 0.17331666\n",
            " 0.23298223 0.1714124  0.156594   0.16646041]\n",
            "Time taken for 1 epoch 8.043047428131104 sec\n",
            "\n",
            "Epoch 28 Batch 0 Loss [0.34178787 0.17654154 0.02781795 0.11217643 0.03994036 0.07609723\n",
            " 0.17153466 0.2190671  0.1902118  0.06269675 0.20296194 0.19441564\n",
            " 0.39787146 0.11529605 0.09413943 0.18468353 0.08975766 0.19051628\n",
            " 0.12742126 0.15148883 0.05593881 0.2071632  0.04583316 0.11769397\n",
            " 0.20714217 0.09983031 0.12126075 0.33406046 0.05056897 0.03502785\n",
            " 0.14843811 0.20144804 0.10754742 0.08676971 0.09668744 0.06920875\n",
            " 0.15730953 0.45684156 0.02141451 0.08452297 0.2394013  0.10868197\n",
            " 0.06355903 0.03402868 0.01424268 0.09591568 0.188005   0.02460794\n",
            " 0.04975732 0.03643024 0.01928749 0.04226481 0.36372545 0.3517207\n",
            " 0.04792817 0.3042446  0.22190808 0.14283533 0.03208523 0.1231332\n",
            " 0.03159539 0.01621808 0.5976971  0.15059315]\n",
            "Epoch 28 Loss [0.14553708 0.11224762 0.13845824 0.15622829 0.14006001 0.18487705\n",
            " 0.13250118 0.13866769 0.15188019 0.13972431 0.13717543 0.1844688\n",
            " 0.1408561  0.15110698 0.15063472 0.1262384  0.14653848 0.13109274\n",
            " 0.11901471 0.1628634  0.13258809 0.13534072 0.17556341 0.15747026\n",
            " 0.15286875 0.16561724 0.13224387 0.158551   0.13483547 0.16132192\n",
            " 0.11675128 0.12963906 0.109229   0.13455588 0.12385596 0.18601698\n",
            " 0.14872669 0.18216679 0.14949779 0.17412709 0.15434137 0.15439717\n",
            " 0.14145426 0.13596494 0.13584715 0.14944404 0.17606707 0.12602673\n",
            " 0.13712773 0.12724425 0.14764027 0.1138815  0.16753857 0.14499754\n",
            " 0.16534483 0.11990126 0.17755976 0.1501065  0.20131548 0.15121628\n",
            " 0.15306176 0.13013454 0.14098458 0.14750528]\n",
            "Time taken for 1 epoch 8.454810619354248 sec\n",
            "\n",
            "Epoch 29 Batch 0 Loss [0.18999127 0.01723204 0.02695769 0.03831812 0.00360384 0.0462212\n",
            " 0.09059295 0.0352014  0.19651842 0.04853923 0.15881395 0.02681305\n",
            " 0.06140122 0.23966841 0.08782333 0.04827428 0.2242806  0.02451772\n",
            " 0.10259253 0.05658095 0.05319377 0.23908612 0.02300124 0.03520637\n",
            " 0.01106169 0.02850963 0.0273449  0.03455242 0.09657709 0.16399969\n",
            " 0.05012108 0.02730451 0.06938248 0.03241155 0.09340602 0.01894464\n",
            " 0.02475576 0.07141915 0.14398201 0.08594004 0.27302873 0.15237683\n",
            " 0.07941466 0.13192126 0.03991816 0.15924491 0.5490542  0.126088\n",
            " 0.05193024 0.21841158 0.02695523 0.16940692 0.10885153 0.1527854\n",
            " 0.10538471 0.07456451 0.10506821 0.3211284  0.1515312  0.1870635\n",
            " 0.31894493 0.06253883 0.2421735  0.05947226]\n",
            "Epoch 29 Loss [0.14975321 0.11606746 0.1159161  0.13837571 0.124345   0.11411899\n",
            " 0.15458897 0.13100034 0.15768488 0.11462184 0.09768671 0.1149558\n",
            " 0.11905592 0.09042285 0.11307886 0.16785221 0.09702244 0.11834729\n",
            " 0.1481747  0.11215976 0.12524197 0.15235531 0.10713443 0.12401123\n",
            " 0.13871704 0.13597368 0.10691497 0.15617083 0.13960804 0.1726054\n",
            " 0.11717607 0.12947437 0.11201571 0.13162868 0.10049787 0.15912598\n",
            " 0.13456015 0.13256358 0.11276633 0.10662241 0.14576729 0.12269914\n",
            " 0.11090054 0.13613637 0.12484843 0.12478749 0.13295573 0.12239998\n",
            " 0.15896279 0.11331645 0.13302197 0.1278162  0.13532469 0.146211\n",
            " 0.10429411 0.09596673 0.1355171  0.14258453 0.13977279 0.10939983\n",
            " 0.11933368 0.1372027  0.11186622 0.10182394]\n",
            "Time taken for 1 epoch 8.03698205947876 sec\n",
            "\n",
            "Epoch 30 Batch 0 Loss [0.07794253 0.10114842 0.14708939 0.0358752  0.03859517 0.1783172\n",
            " 0.0393858  0.02376773 0.13210413 0.18907177 0.00459502 0.07696435\n",
            " 0.0411139  0.0357275  0.03243193 0.04305371 0.00626632 0.0578851\n",
            " 0.04966185 0.01656313 0.10565951 0.0426112  0.09620915 0.06013855\n",
            " 0.17956239 0.22032894 0.01237852 0.05128156 0.09447492 0.0345467\n",
            " 0.03236718 0.12346904 0.14066263 0.02724212 0.09282165 0.05894816\n",
            " 0.16171521 0.07135921 0.04949657 0.08918177 0.1945361  0.04818552\n",
            " 0.12859201 0.07504819 0.03668531 0.11697724 0.09620007 0.1331477\n",
            " 0.03026969 0.16169523 0.02326222 0.07780936 0.1868127  0.0510288\n",
            " 0.08116819 0.14846355 0.19483408 0.14250867 0.00681182 0.05678964\n",
            " 0.1094353  0.0953365  0.04245111 0.08119632]\n",
            "Epoch 30 Loss [0.09284001 0.08536319 0.1255905  0.10730647 0.11781695 0.11542714\n",
            " 0.084245   0.10768923 0.08289889 0.11145806 0.11076087 0.1002477\n",
            " 0.1360968  0.12632334 0.10805473 0.09346412 0.10389868 0.09607709\n",
            " 0.11146758 0.10030554 0.10286514 0.0990855  0.10989641 0.08714631\n",
            " 0.09346937 0.10127185 0.12663275 0.12893686 0.10490303 0.09851777\n",
            " 0.08431822 0.08935573 0.10031984 0.10015811 0.10396824 0.09629776\n",
            " 0.11219426 0.10377851 0.12006293 0.09542383 0.12268806 0.08814439\n",
            " 0.10643989 0.10409039 0.08437148 0.10585053 0.11554531 0.10359166\n",
            " 0.12295524 0.12350694 0.1212751  0.14946298 0.0926459  0.10043351\n",
            " 0.11263129 0.10183269 0.08776357 0.12962084 0.08182726 0.09529\n",
            " 0.11928071 0.07584682 0.08473765 0.12668432]\n",
            "Time taken for 1 epoch 8.464056015014648 sec\n",
            "\n",
            "Epoch 31 Batch 0 Loss [0.07583749 0.07839135 0.24049023 0.17661549 0.01124025 0.02154249\n",
            " 0.04791524 0.04104948 0.01235284 0.11338829 0.09077175 0.0418553\n",
            " 0.05350563 0.17518915 0.01197006 0.31248227 0.01861192 0.02132869\n",
            " 0.03643009 0.1121731  0.03460203 0.15309748 0.03587619 0.04396151\n",
            " 0.04204105 0.09037174 0.21358092 0.03112803 0.01905541 0.04361146\n",
            " 0.01658355 0.07859541 0.02271384 0.16097327 0.03361502 0.05808765\n",
            " 0.12550144 0.1291274  0.10884524 0.20026773 0.04954668 0.07966441\n",
            " 0.02872901 0.02972104 0.04794719 0.02856304 0.05425811 0.03704378\n",
            " 0.04344391 0.00233408 0.18564071 0.0423587  0.17161645 0.02582955\n",
            " 0.02399733 0.01673793 0.11669461 0.02734837 0.10624021 0.02019289\n",
            " 0.3071317  0.12746342 0.01306605 0.02658035]\n",
            "Epoch 31 Loss [0.09929892 0.06201484 0.0902052  0.08452033 0.09075204 0.07804077\n",
            " 0.07832032 0.07517583 0.08970746 0.08833955 0.07370508 0.07925449\n",
            " 0.09555443 0.09590238 0.10328506 0.10116956 0.07050443 0.09193335\n",
            " 0.07162906 0.08925126 0.06098658 0.07613477 0.08472346 0.07346804\n",
            " 0.07305889 0.08433707 0.06405699 0.08129113 0.08753206 0.07025126\n",
            " 0.10907444 0.09163547 0.06878765 0.09643308 0.09179237 0.08136641\n",
            " 0.0884934  0.09869416 0.09616273 0.07159986 0.11200147 0.08523891\n",
            " 0.09011434 0.07280369 0.08256961 0.09975048 0.09214214 0.07380167\n",
            " 0.08185849 0.0712827  0.087841   0.08346327 0.08319833 0.0747677\n",
            " 0.09540252 0.09020188 0.05917469 0.0674006  0.10196304 0.08235336\n",
            " 0.09644664 0.08651707 0.11227196 0.09714821]\n",
            "Time taken for 1 epoch 8.06386137008667 sec\n",
            "\n",
            "Epoch 32 Batch 0 Loss [0.10697101 0.1197545  0.13225648 0.02363751 0.04504716 0.04168848\n",
            " 0.05633277 0.02819214 0.05379219 0.00958968 0.29945463 0.01621554\n",
            " 0.02033382 0.03412015 0.03049856 0.00684173 0.03424573 0.01515324\n",
            " 0.07871471 0.0429857  0.0797376  0.03114785 0.01536938 0.01578582\n",
            " 0.03520239 0.03718056 0.12872604 0.10665455 0.00575687 0.0908785\n",
            " 0.03429304 0.02057107 0.06792573 0.06780792 0.04997041 0.03723121\n",
            " 0.01563932 0.09584554 0.02905452 0.00813124 0.17007281 0.03159584\n",
            " 0.06288582 0.03528094 0.02554426 0.10202951 0.13237584 0.0186916\n",
            " 0.03713224 0.03138335 0.01773891 0.05053498 0.02087719 0.01675128\n",
            " 0.02563619 0.03330082 0.04005713 0.05191528 0.0711313  0.01415789\n",
            " 0.06726939 0.04287835 0.07030334 0.01424097]\n",
            "Epoch 32 Loss [0.06997367 0.07180147 0.05993676 0.0561295  0.06539628 0.08354454\n",
            " 0.05380525 0.0723215  0.07641461 0.06517181 0.07413748 0.05727245\n",
            " 0.06906788 0.06149503 0.06751554 0.06753959 0.07003767 0.05177139\n",
            " 0.04817804 0.06095901 0.07241594 0.06257366 0.05144696 0.06755951\n",
            " 0.06451464 0.06709751 0.0611301  0.0662519  0.06128029 0.08235104\n",
            " 0.09771159 0.0685351  0.07272506 0.06184211 0.05689771 0.05926263\n",
            " 0.08129309 0.06365046 0.07409723 0.07064478 0.07139683 0.0619446\n",
            " 0.06326655 0.06403927 0.06544217 0.08536752 0.06236685 0.07150415\n",
            " 0.09646522 0.06681286 0.06378898 0.07735464 0.07292625 0.0582203\n",
            " 0.07457836 0.05983446 0.05307084 0.08026291 0.06257138 0.06861363\n",
            " 0.07027356 0.05530231 0.07140164 0.07369146]\n",
            "Time taken for 1 epoch 8.487568140029907 sec\n",
            "\n",
            "Epoch 33 Batch 0 Loss [0.07646308 0.02356308 0.02565221 0.14119072 0.01349782 0.01175879\n",
            " 0.00814374 0.03466434 0.02733817 0.08577636 0.01231949 0.09617087\n",
            " 0.02346572 0.05007259 0.03740467 0.01760127 0.04647708 0.01323096\n",
            " 0.04485514 0.05362743 0.01486517 0.01224735 0.02257254 0.03692264\n",
            " 0.0154029  0.02125398 0.04347574 0.10021847 0.07829332 0.09633619\n",
            " 0.07765453 0.02812888 0.07316206 0.06381641 0.05453259 0.01269716\n",
            " 0.03423445 0.03738528 0.00336199 0.04764745 0.02590126 0.01737959\n",
            " 0.0839323  0.01291259 0.04581451 0.01709068 0.0439298  0.06654734\n",
            " 0.0040668  0.10491421 0.04539709 0.15196784 0.09427423 0.02734932\n",
            " 0.033854   0.01729221 0.02022705 0.07614333 0.01836326 0.02295328\n",
            " 0.00766389 0.03364641 0.02317873 0.03303707]\n",
            "Epoch 33 Loss [0.06320984 0.05520586 0.0528183  0.04971961 0.06358173 0.06534699\n",
            " 0.05477156 0.06905894 0.05451686 0.05591643 0.05697158 0.04839522\n",
            " 0.05900295 0.05497451 0.07720169 0.05618178 0.06406491 0.05058778\n",
            " 0.05018773 0.06668129 0.04493369 0.05293349 0.05692948 0.05852006\n",
            " 0.047837   0.05919021 0.05999839 0.07120853 0.05550356 0.04616817\n",
            " 0.04961357 0.05489287 0.05774444 0.05930226 0.04930814 0.04456862\n",
            " 0.07220167 0.05907999 0.05572826 0.07001825 0.04241248 0.06636804\n",
            " 0.0532924  0.04861118 0.05350571 0.05045171 0.03215782 0.04828952\n",
            " 0.05931314 0.05459749 0.04332545 0.06299356 0.04398287 0.05589086\n",
            " 0.06768721 0.05719558 0.04531117 0.04115349 0.04894749 0.06372151\n",
            " 0.05398273 0.05592883 0.07150216 0.04375426]\n",
            "Time taken for 1 epoch 8.08828592300415 sec\n",
            "\n",
            "Epoch 34 Batch 0 Loss [0.03428659 0.02506758 0.02902103 0.03242778 0.0719405  0.01108646\n",
            " 0.01259916 0.03698571 0.00526536 0.00092155 0.00415687 0.04491434\n",
            " 0.01815487 0.04303157 0.01489147 0.04891928 0.01009329 0.04537549\n",
            " 0.02769625 0.05672742 0.05107835 0.01874819 0.00488122 0.00425801\n",
            " 0.03649975 0.02945643 0.0571867  0.00298252 0.0274125  0.00936617\n",
            " 0.01171379 0.16230868 0.01257159 0.04711921 0.03127    0.01072567\n",
            " 0.0024825  0.03046415 0.03265815 0.00675632 0.05880899 0.02927258\n",
            " 0.00927013 0.04840161 0.15911327 0.01524689 0.01869917 0.01307455\n",
            " 0.00651645 0.05864005 0.00939673 0.02411781 0.03348362 0.02514617\n",
            " 0.0066226  0.00858628 0.01728277 0.10883618 0.04020669 0.02366658\n",
            " 0.02130864 0.0834826  0.0511521  0.05367777]\n",
            "Epoch 34 Loss [0.03927607 0.04568253 0.04341161 0.03699945 0.04048647 0.06076537\n",
            " 0.04680773 0.04700712 0.04018874 0.04237974 0.0380872  0.04835856\n",
            " 0.03963412 0.04715125 0.05490749 0.04183181 0.03465357 0.03779471\n",
            " 0.05054137 0.04687037 0.03460262 0.04779649 0.04596765 0.04985219\n",
            " 0.06448261 0.0362503  0.04267653 0.03828692 0.04308212 0.04535009\n",
            " 0.0398684  0.05258656 0.04451451 0.04390061 0.04558551 0.04038811\n",
            " 0.04315865 0.05538678 0.04851449 0.04913777 0.05064191 0.04953076\n",
            " 0.03570157 0.04659064 0.05198033 0.043088   0.03399223 0.04634814\n",
            " 0.04448572 0.03945648 0.04146401 0.03891664 0.0567157  0.03847046\n",
            " 0.05506684 0.04487597 0.04063848 0.04926927 0.05345945 0.02464152\n",
            " 0.04575939 0.04673214 0.03919232 0.05950809]\n",
            "Time taken for 1 epoch 8.4714674949646 sec\n",
            "\n",
            "Epoch 35 Batch 0 Loss [0.02018566 0.07825715 0.00810908 0.01156141 0.00183136 0.00862012\n",
            " 0.05648955 0.04646419 0.06580289 0.01446216 0.01441666 0.01913296\n",
            " 0.01048463 0.0390179  0.00750267 0.00720739 0.01046045 0.03719634\n",
            " 0.03981554 0.04605839 0.02169383 0.02372275 0.05241688 0.01057012\n",
            " 0.13050936 0.03175282 0.01243799 0.01946095 0.05630425 0.02038413\n",
            " 0.04197641 0.00576916 0.05120932 0.01279377 0.11167885 0.00605027\n",
            " 0.01421661 0.00766864 0.01548696 0.02838284 0.01113521 0.00972018\n",
            " 0.01666247 0.02679302 0.00426064 0.02253729 0.01224956 0.0364155\n",
            " 0.0077293  0.00412222 0.21904936 0.01201365 0.00927265 0.04472348\n",
            " 0.07691916 0.00541762 0.05358982 0.16380124 0.00051824 0.02992154\n",
            " 0.01207288 0.01099506 0.1049114  0.04249797]\n",
            "Epoch 35 Loss [0.0350607  0.03341507 0.03163511 0.03516362 0.0390793  0.04608909\n",
            " 0.04175249 0.04163368 0.03922206 0.04724528 0.04470209 0.04283921\n",
            " 0.0524067  0.03202787 0.04079505 0.03541111 0.04169156 0.02426945\n",
            " 0.04138438 0.03001065 0.04699119 0.04923156 0.04000819 0.03135817\n",
            " 0.03871147 0.03958068 0.0288504  0.03650897 0.03625887 0.03829085\n",
            " 0.04005996 0.03596981 0.02523875 0.05790484 0.04217931 0.03902796\n",
            " 0.05163412 0.0323189  0.03369413 0.03421276 0.04018858 0.02936128\n",
            " 0.0376923  0.03007183 0.03309563 0.0361286  0.03350734 0.03495743\n",
            " 0.04851767 0.03153212 0.04324057 0.03083579 0.03796303 0.04589014\n",
            " 0.04007153 0.04647717 0.04411928 0.04110784 0.03360526 0.04550361\n",
            " 0.02828653 0.02843779 0.03325481 0.02748239]\n",
            "Time taken for 1 epoch 8.085556745529175 sec\n",
            "\n",
            "Epoch 36 Batch 0 Loss [0.11151632 0.01001687 0.0085766  0.01294535 0.01291259 0.04315073\n",
            " 0.02972787 0.01576439 0.06408563 0.07792851 0.01493584 0.03387775\n",
            " 0.08060498 0.00927267 0.04314565 0.02428091 0.00965152 0.01526734\n",
            " 0.00570395 0.01713901 0.01169841 0.02988116 0.0131882  0.00526094\n",
            " 0.02762681 0.01484311 0.0195099  0.14970845 0.01850165 0.01732488\n",
            " 0.00637565 0.10987454 0.01085123 0.01778072 0.02145418 0.00955989\n",
            " 0.0150208  0.02703262 0.0094229  0.00789815 0.01400129 0.00032592\n",
            " 0.00715918 0.02227337 0.10059375 0.03579585 0.07473161 0.02340461\n",
            " 0.02882246 0.00558144 0.19042242 0.01959521 0.01677037 0.0044028\n",
            " 0.00711405 0.05675855 0.00337349 0.01480653 0.13228743 0.02539302\n",
            " 0.01184092 0.04488937 0.0164217  0.03505029]\n",
            "Epoch 36 Loss [0.04451445 0.04409496 0.03527648 0.02210723 0.03097948 0.02986683\n",
            " 0.03752961 0.04085089 0.03953856 0.03277539 0.02547546 0.03323856\n",
            " 0.03611881 0.02812479 0.0295171  0.02454398 0.0225314  0.02014646\n",
            " 0.02449692 0.0317186  0.02422851 0.02488248 0.02820559 0.03027196\n",
            " 0.02429901 0.03178446 0.03692818 0.03369263 0.03258329 0.03589308\n",
            " 0.04268746 0.02786668 0.03371947 0.0261292  0.03162317 0.03224015\n",
            " 0.03383455 0.02886776 0.02568836 0.02503654 0.0243336  0.03112425\n",
            " 0.02668457 0.02639865 0.03277404 0.02562086 0.04192016 0.03929909\n",
            " 0.02329242 0.03578057 0.04014095 0.03803895 0.03738096 0.01730599\n",
            " 0.03951143 0.02191018 0.02146947 0.02042434 0.02433929 0.02402537\n",
            " 0.02408953 0.02687521 0.0301786  0.03605819]\n",
            "Time taken for 1 epoch 8.489057779312134 sec\n",
            "\n",
            "Epoch 37 Batch 0 Loss [0.01994904 0.01908065 0.01353834 0.02728075 0.00468213 0.00967075\n",
            " 0.01504256 0.01107554 0.08571228 0.02526107 0.00935463 0.01312668\n",
            " 0.15957212 0.00407018 0.01678619 0.01251197 0.00896176 0.01507663\n",
            " 0.00466736 0.01389505 0.00622678 0.02403895 0.01248511 0.02892484\n",
            " 0.01550525 0.00521187 0.00836175 0.01250809 0.00618275 0.01580871\n",
            " 0.00244684 0.01353643 0.01045629 0.00901739 0.01934491 0.00555001\n",
            " 0.0184297  0.01066844 0.01504397 0.1294078  0.0103962  0.00578661\n",
            " 0.00432744 0.02736601 0.01114631 0.00622219 0.00984838 0.00827519\n",
            " 0.033751   0.00451952 0.03034064 0.01494513 0.02524058 0.02674266\n",
            " 0.02984862 0.02748108 0.04851607 0.05608338 0.01143216 0.09987728\n",
            " 0.03254692 0.0081919  0.00406953 0.13937041]\n",
            "Epoch 37 Loss [0.01892905 0.03668102 0.02702465 0.03981033 0.01860198 0.0285289\n",
            " 0.03473924 0.0247226  0.02663454 0.03951663 0.0383295  0.02662022\n",
            " 0.02439175 0.02284226 0.03204514 0.02526884 0.02440661 0.03615911\n",
            " 0.02600462 0.035796   0.02695298 0.0364223  0.02671852 0.02464129\n",
            " 0.02094306 0.03454168 0.02605676 0.02226609 0.02793287 0.03366949\n",
            " 0.03363092 0.02896755 0.03657514 0.0270886  0.04338507 0.02917544\n",
            " 0.02272852 0.01963526 0.02231809 0.02960225 0.03206639 0.02645262\n",
            " 0.02130606 0.01447231 0.01947113 0.01762909 0.02879844 0.02873655\n",
            " 0.02395853 0.03690677 0.02306006 0.02687164 0.01712997 0.02429698\n",
            " 0.02616416 0.01548663 0.03593767 0.03621457 0.0265875  0.03075579\n",
            " 0.02773186 0.02230348 0.02733724 0.02861449]\n",
            "Time taken for 1 epoch 8.067896604537964 sec\n",
            "\n",
            "Epoch 38 Batch 0 Loss [0.01312711 0.00535661 0.00997794 0.01392236 0.00561253 0.00842458\n",
            " 0.05530038 0.11814838 0.00222471 0.00509872 0.00538765 0.00303089\n",
            " 0.01051609 0.01231034 0.00939025 0.03365919 0.01102529 0.00915331\n",
            " 0.00629358 0.00680507 0.01239503 0.00704911 0.01147213 0.01739281\n",
            " 0.00301006 0.00710619 0.00749653 0.01429302 0.0069686  0.01161979\n",
            " 0.0100692  0.00953551 0.00749606 0.02833539 0.02279145 0.00772202\n",
            " 0.00751178 0.008707   0.05146997 0.01814665 0.01176381 0.01366205\n",
            " 0.00903047 0.02684041 0.01926138 0.00794278 0.00447655 0.11760715\n",
            " 0.0079273  0.01655952 0.07781368 0.02395709 0.01656781 0.02339684\n",
            " 0.00829019 0.01046067 0.01872725 0.01081619 0.03342943 0.03990954\n",
            " 0.01109463 0.00877794 0.12153704 0.01525185]\n",
            "Epoch 38 Loss [0.01407543 0.03391397 0.0282296  0.02903572 0.01157543 0.02193844\n",
            " 0.02132697 0.01902673 0.01477631 0.01279688 0.02089964 0.01871662\n",
            " 0.01487122 0.03174397 0.03596715 0.02461093 0.02022145 0.03105996\n",
            " 0.01677687 0.02007004 0.01956014 0.02730528 0.01634753 0.0224137\n",
            " 0.03210935 0.02968084 0.02501371 0.01952199 0.01944594 0.0195353\n",
            " 0.02385112 0.0410019  0.01446305 0.01550129 0.02243369 0.02851981\n",
            " 0.01746221 0.01945696 0.01459691 0.02858392 0.02604852 0.02345744\n",
            " 0.02075448 0.0267844  0.01778782 0.02297964 0.01745268 0.02101917\n",
            " 0.04558082 0.02064472 0.02343224 0.01688809 0.02374271 0.02908765\n",
            " 0.0289559  0.04420014 0.02362425 0.01782742 0.02511921 0.02040887\n",
            " 0.0292187  0.01971133 0.01986527 0.01988093]\n",
            "Time taken for 1 epoch 8.468387842178345 sec\n",
            "\n",
            "Epoch 39 Batch 0 Loss [0.00345108 0.01318378 0.00099131 0.00722911 0.03371646 0.00247537\n",
            " 0.0032095  0.01698756 0.02097936 0.00807756 0.01847477 0.02547173\n",
            " 0.0183164  0.01097326 0.0059425  0.00340942 0.00937275 0.00709167\n",
            " 0.00874648 0.00473547 0.01270322 0.0041901  0.00438629 0.00849126\n",
            " 0.01585509 0.08989975 0.00213372 0.00706515 0.01679605 0.00462366\n",
            " 0.01720117 0.00166673 0.01349356 0.01320194 0.07788104 0.0090185\n",
            " 0.02283276 0.01631632 0.01904476 0.01340041 0.00521319 0.00323601\n",
            " 0.00668657 0.02234058 0.00598109 0.01037824 0.01095594 0.01598254\n",
            " 0.00978632 0.00886582 0.00660786 0.01391231 0.01157002 0.00590235\n",
            " 0.00614667 0.00457465 0.0050463  0.00774272 0.03958236 0.00676123\n",
            " 0.01920523 0.02158197 0.00862538 0.01471439]\n",
            "Epoch 39 Loss [0.0170511  0.024599   0.02651868 0.02237099 0.02252276 0.02359631\n",
            " 0.02036154 0.02844365 0.02846047 0.02325141 0.01678864 0.02055561\n",
            " 0.02709669 0.01975555 0.01610645 0.02791585 0.02722182 0.01938116\n",
            " 0.02341634 0.02057007 0.02575783 0.01904294 0.01686583 0.01534389\n",
            " 0.01910735 0.01908367 0.02123245 0.01270213 0.02833777 0.02133719\n",
            " 0.02195901 0.02971586 0.01346176 0.01031129 0.01650682 0.01987807\n",
            " 0.02304081 0.02649332 0.02649602 0.0130477  0.01386046 0.0171799\n",
            " 0.02266749 0.01753263 0.02031733 0.02326203 0.01975283 0.0268291\n",
            " 0.01886562 0.02252259 0.02113204 0.0159594  0.0376053  0.01680047\n",
            " 0.01173522 0.04316276 0.02016822 0.0185191  0.01566594 0.01870595\n",
            " 0.0228733  0.01066222 0.02071989 0.02516647]\n",
            "Time taken for 1 epoch 8.073569297790527 sec\n",
            "\n",
            "Epoch 40 Batch 0 Loss [0.00324226 0.0533774  0.0051956  0.04796867 0.00344327 0.00350696\n",
            " 0.00869092 0.01208514 0.0107983  0.03116244 0.02074293 0.09674923\n",
            " 0.04097912 0.01466577 0.00334769 0.01080297 0.01849767 0.01532419\n",
            " 0.01296246 0.00945842 0.01618982 0.01054522 0.00821223 0.00961662\n",
            " 0.00611997 0.00523684 0.00687545 0.00957585 0.00536458 0.00427135\n",
            " 0.00612744 0.00806372 0.01934014 0.0058989  0.0104374  0.00802891\n",
            " 0.00153991 0.0086693  0.00815744 0.01123216 0.00748686 0.01963415\n",
            " 0.00513549 0.01885865 0.02497801 0.01165636 0.00323541 0.00430336\n",
            " 0.00228059 0.05368614 0.00558764 0.00978896 0.00809703 0.00867311\n",
            " 0.00103558 0.00349165 0.01441922 0.0042204  0.00878285 0.01102712\n",
            " 0.00280693 0.0054106  0.00374065 0.00574868]\n",
            "Epoch 40 Loss [0.01190159 0.01483602 0.0196682  0.01736782 0.01448927 0.01408219\n",
            " 0.02437401 0.01918804 0.01223515 0.02980451 0.01666667 0.01655574\n",
            " 0.00936614 0.03869731 0.02514873 0.0121834  0.01894142 0.02434399\n",
            " 0.02094623 0.01358551 0.0207994  0.00789868 0.01353869 0.02214681\n",
            " 0.01430599 0.02059978 0.02164077 0.01002234 0.01523214 0.02676097\n",
            " 0.02529148 0.01962375 0.01921887 0.0140871  0.02984439 0.02651706\n",
            " 0.0219277  0.01933898 0.02152348 0.01743271 0.01677085 0.01759507\n",
            " 0.01446802 0.01390362 0.01017936 0.01497348 0.02016263 0.01596573\n",
            " 0.02128898 0.01989987 0.01456956 0.03706597 0.01176944 0.01676671\n",
            " 0.02603393 0.01722188 0.03132029 0.0446604  0.01608727 0.01865511\n",
            " 0.01396846 0.02237321 0.02158803 0.0195953 ]\n",
            "Time taken for 1 epoch 8.474002361297607 sec\n",
            "\n",
            "Epoch 41 Batch 0 Loss [0.01771642 0.00246019 0.00191745 0.00103797 0.01188428 0.01116256\n",
            " 0.00960466 0.00540804 0.01258575 0.00619827 0.011364   0.00368304\n",
            " 0.01316623 0.00923899 0.00894755 0.00915755 0.00488544 0.00640412\n",
            " 0.01974838 0.00686108 0.00731108 0.00519347 0.01093869 0.004456\n",
            " 0.001493   0.07772169 0.00668996 0.00697998 0.00701414 0.07883784\n",
            " 0.01331083 0.00266524 0.00306828 0.02701499 0.00250544 0.00596158\n",
            " 0.00126699 0.00299087 0.0039836  0.00452555 0.01549404 0.05075585\n",
            " 0.00170852 0.18291546 0.12343124 0.01698824 0.00821868 0.00361802\n",
            " 0.00438473 0.01407537 0.00492564 0.00554782 0.01240116 0.00289582\n",
            " 0.00293122 0.00760058 0.1091078  0.00659297 0.0093463  0.01202941\n",
            " 0.00543039 0.00553537 0.00472051 0.00323745]\n",
            "Epoch 41 Loss [0.01038056 0.02710895 0.01924285 0.01441216 0.01832857 0.01831172\n",
            " 0.01430793 0.00883869 0.02642795 0.02371107 0.02003589 0.00976812\n",
            " 0.01206824 0.02536824 0.01637584 0.01071657 0.03185847 0.00616804\n",
            " 0.02306043 0.01942437 0.01559177 0.0201636  0.0247206  0.01180095\n",
            " 0.01375287 0.01823268 0.02019699 0.02296375 0.03226487 0.01758212\n",
            " 0.01249301 0.0187851  0.01864791 0.01489547 0.01104354 0.02536983\n",
            " 0.01464307 0.01685728 0.01380454 0.02953004 0.01914939 0.02235211\n",
            " 0.0152401  0.01627025 0.03049618 0.0197787  0.01147072 0.0110881\n",
            " 0.01967705 0.01106801 0.0107143  0.0208196  0.02322526 0.0166532\n",
            " 0.01539328 0.04482287 0.02214265 0.01687041 0.01032695 0.02275603\n",
            " 0.01594276 0.02843762 0.02047077 0.03398142]\n",
            "Time taken for 1 epoch 8.041550159454346 sec\n",
            "\n",
            "Epoch 42 Batch 0 Loss [0.00354611 0.01061257 0.00520992 0.00172408 0.00500748 0.172911\n",
            " 0.00987193 0.00258687 0.00972265 0.00200792 0.024677   0.00363854\n",
            " 0.00080306 0.00825648 0.00397586 0.00623025 0.00339833 0.00675439\n",
            " 0.00558341 0.00999735 0.0021154  0.14933701 0.00459896 0.00133331\n",
            " 0.01441986 0.00591986 0.00080545 0.00977221 0.00425523 0.0037846\n",
            " 0.00873397 0.10389978 0.00845319 0.00433037 0.00797411 0.0078456\n",
            " 0.01134795 0.00858678 0.00461712 0.00727044 0.01095712 0.01842679\n",
            " 0.00799374 0.01517398 0.01388759 0.0022639  0.00723207 0.00220171\n",
            " 0.00689481 0.0051049  0.01630039 0.01069675 0.00429857 0.00642375\n",
            " 0.01569849 0.0023419  0.00428989 0.00343226 0.00845948 0.00324725\n",
            " 0.04264241 0.00744311 0.06113427 0.0052805 ]\n",
            "Epoch 42 Loss [0.01683968 0.01372507 0.03054215 0.01411344 0.03196542 0.02474048\n",
            " 0.01133486 0.00686725 0.01797728 0.01527419 0.01198571 0.02739803\n",
            " 0.03113052 0.01489288 0.00767298 0.01468831 0.0165706  0.0143234\n",
            " 0.01668246 0.01595173 0.01286727 0.02053359 0.01583901 0.0249047\n",
            " 0.01919226 0.01130777 0.02062112 0.02284461 0.00787599 0.01766505\n",
            " 0.00865202 0.03866755 0.05334547 0.02164066 0.01070706 0.00825397\n",
            " 0.01912545 0.02134032 0.0145413  0.01290864 0.02224917 0.0175513\n",
            " 0.00813583 0.01300606 0.03286838 0.01785784 0.01047186 0.01422724\n",
            " 0.01657777 0.01096404 0.01343889 0.03025536 0.01365674 0.01817799\n",
            " 0.0108957  0.00830343 0.01920448 0.00752552 0.0137008  0.02135262\n",
            " 0.02474442 0.01870214 0.01940177 0.01615523]\n",
            "Time taken for 1 epoch 8.546319723129272 sec\n",
            "\n",
            "Epoch 43 Batch 0 Loss [0.00875671 0.00174979 0.00278933 0.00908746 0.00816013 0.00389101\n",
            " 0.00960254 0.01386573 0.01552836 0.0060206  0.00218827 0.01318027\n",
            " 0.00197994 0.00471018 0.00564172 0.00688077 0.01025761 0.00610785\n",
            " 0.00671755 0.03014332 0.00406575 0.01225982 0.00441566 0.00420937\n",
            " 0.00245264 0.0069585  0.00511371 0.00164548 0.00815861 0.00475125\n",
            " 0.00431292 0.00456907 0.0079513  0.00664754 0.00273707 0.0015978\n",
            " 0.0042024  0.00355041 0.0060967  0.00398414 0.02569161 0.00086943\n",
            " 0.00840314 0.13362263 0.00462197 0.0015738  0.09794328 0.01171628\n",
            " 0.00228668 0.00295833 0.00501738 0.00162846 0.00486332 0.00668271\n",
            " 0.0036283  0.00284559 0.00567097 0.00686169 0.01338256 0.00272235\n",
            " 0.00229368 0.01562002 0.00737267 0.01532171]\n",
            "Epoch 43 Loss [0.01059132 0.01583724 0.0120627  0.02194521 0.02529599 0.0191131\n",
            " 0.02829728 0.01429714 0.0207406  0.00762134 0.0091943  0.03350946\n",
            " 0.01117825 0.01217304 0.01896102 0.00591566 0.02337209 0.0193351\n",
            " 0.01172222 0.02175513 0.01362436 0.01888338 0.00971602 0.0161349\n",
            " 0.01432313 0.0228143  0.01820075 0.02161478 0.01117978 0.02005944\n",
            " 0.01754315 0.01227707 0.013096   0.02187791 0.01262658 0.01868594\n",
            " 0.01700296 0.011369   0.0192959  0.02676931 0.0251567  0.01360104\n",
            " 0.01721364 0.02044623 0.02238348 0.01718726 0.01256346 0.02437422\n",
            " 0.01429825 0.02947523 0.01231249 0.01936384 0.02193731 0.01480749\n",
            " 0.02063233 0.01249883 0.00992957 0.01386504 0.02146874 0.01267089\n",
            " 0.01214492 0.00824094 0.01067786 0.01768339]\n",
            "Time taken for 1 epoch 8.052283763885498 sec\n",
            "\n",
            "Epoch 44 Batch 0 Loss [0.00992386 0.00293335 0.00103618 0.00854884 0.00921293 0.00627159\n",
            " 0.00504777 0.00208415 0.00304858 0.00176528 0.00141387 0.04025185\n",
            " 0.08915506 0.02805149 0.22449262 0.00225374 0.00535394 0.03416047\n",
            " 0.00292812 0.03476017 0.00500301 0.0080129  0.00282169 0.00523908\n",
            " 0.00624745 0.001812   0.00256509 0.00271529 0.00986406 0.00285958\n",
            " 0.00510166 0.00545621 0.01177274 0.00471853 0.00639362 0.02807367\n",
            " 0.01593256 0.00144293 0.11132826 0.00346326 0.00357385 0.00395883\n",
            " 0.1966876  0.00203577 0.00252378 0.00333449 0.00406626 0.00337281\n",
            " 0.01001052 0.01452814 0.00584885 0.00203494 0.00297253 0.00207637\n",
            " 0.1152129  0.06255054 0.00470928 0.00551426 0.0007481  0.00198399\n",
            " 0.00180014 0.0012313  0.00538391 0.00302853]\n",
            "Epoch 44 Loss [0.01130469 0.01585151 0.01892776 0.01411019 0.0110633  0.0095874\n",
            " 0.00748979 0.01762614 0.00740642 0.02066154 0.01055877 0.01048011\n",
            " 0.01248914 0.01773003 0.02414999 0.01633345 0.01131463 0.01355159\n",
            " 0.01288456 0.01971338 0.04489709 0.01659622 0.02202614 0.01972111\n",
            " 0.00620357 0.01214233 0.0131552  0.01842988 0.01139135 0.00960573\n",
            " 0.02638154 0.03930713 0.00529102 0.02387739 0.00805464 0.00952518\n",
            " 0.02548213 0.02823236 0.01581399 0.02143879 0.01977798 0.02604103\n",
            " 0.0183423  0.00759056 0.01931122 0.01756696 0.02165562 0.02074729\n",
            " 0.01895314 0.01330678 0.0370213  0.01627377 0.0156152  0.00591279\n",
            " 0.01742914 0.00664865 0.02242006 0.02393159 0.01210748 0.01574177\n",
            " 0.02284537 0.0073058  0.00685643 0.02286665]\n",
            "Time taken for 1 epoch 8.446828842163086 sec\n",
            "\n",
            "Epoch 45 Batch 0 Loss [0.00308629 0.00417183 0.00331099 0.06648553 0.00383609 0.00288015\n",
            " 0.00214975 0.00619804 0.00853079 0.00676997 0.01313333 0.00877409\n",
            " 0.00431171 0.10097566 0.00779502 0.00644369 0.00310713 0.00471856\n",
            " 0.00679692 0.00402577 0.00340525 0.00676917 0.00745774 0.00562279\n",
            " 0.0075803  0.00258036 0.05750296 0.00620683 0.00225483 0.00163316\n",
            " 0.00149605 0.00738513 0.00447616 0.00559326 0.00418454 0.00524668\n",
            " 0.00877292 0.01137658 0.00476361 0.00163561 0.00552701 0.00435566\n",
            " 0.00639514 0.00376015 0.00532585 0.00280514 0.0012264  0.00468839\n",
            " 0.01330181 0.00349099 0.00570202 0.00313513 0.00642085 0.00609312\n",
            " 0.0037033  0.0025075  0.01094524 0.01183343 0.00657786 0.00339702\n",
            " 0.00099108 0.00123534 0.11334706 0.01588369]\n",
            "Epoch 45 Loss [0.01624335 0.00769854 0.01520463 0.01464764 0.01111482 0.01341899\n",
            " 0.01118257 0.01720927 0.0204467  0.01229145 0.00871549 0.00936161\n",
            " 0.01128713 0.02316251 0.01746439 0.0238403  0.01969335 0.01730193\n",
            " 0.00948335 0.01286543 0.02588235 0.01184114 0.01074381 0.00932441\n",
            " 0.01595918 0.01341268 0.00828294 0.01580066 0.01984643 0.011388\n",
            " 0.00983188 0.02275951 0.01604591 0.02188872 0.01176566 0.01607703\n",
            " 0.01617722 0.02355111 0.01411288 0.00905754 0.02499403 0.01418664\n",
            " 0.02151235 0.02270146 0.00971394 0.02439405 0.02454639 0.00626993\n",
            " 0.01361643 0.0072792  0.01381783 0.01908772 0.00516261 0.01199074\n",
            " 0.00880364 0.02078553 0.01708785 0.00957897 0.0085004  0.01829242\n",
            " 0.00985659 0.02887615 0.01392975 0.01908898]\n",
            "Time taken for 1 epoch 8.062559843063354 sec\n",
            "\n",
            "Epoch 46 Batch 0 Loss [0.00219169 0.00322167 0.00949393 0.01179009 0.0058179  0.00803935\n",
            " 0.00436133 0.00868786 0.00551948 0.00200865 0.00151199 0.00776275\n",
            " 0.00871651 0.00727092 0.00330345 0.01094039 0.00524572 0.00826279\n",
            " 0.04263014 0.02236852 0.00425347 0.00955084 0.0070392  0.0024426\n",
            " 0.00383937 0.00486705 0.00165238 0.00437145 0.15294631 0.00272838\n",
            " 0.0114061  0.0040962  0.00538386 0.00109313 0.11483909 0.01174985\n",
            " 0.1120548  0.00551142 0.00662396 0.00047675 0.00494426 0.0051028\n",
            " 0.01184885 0.00200747 0.00262835 0.00094357 0.00759644 0.00591015\n",
            " 0.0043803  0.00175421 0.00472312 0.11094841 0.00340089 0.00526392\n",
            " 0.00569893 0.00158529 0.00357453 0.00253976 0.00800528 0.00888293\n",
            " 0.014624   0.00320174 0.00847729 0.0055529 ]\n",
            "Epoch 46 Loss [0.02407968 0.01092122 0.02333246 0.01602142 0.02173146 0.00647279\n",
            " 0.02482755 0.02274025 0.00989887 0.02408529 0.01737773 0.02120128\n",
            " 0.0068042  0.00472302 0.01992752 0.01854463 0.01632917 0.00603561\n",
            " 0.01449726 0.01015315 0.01568702 0.01481205 0.01585332 0.03230808\n",
            " 0.00831475 0.0173265  0.01913407 0.03028877 0.01778575 0.00920179\n",
            " 0.01945842 0.00887928 0.01774907 0.00793332 0.02520214 0.01560683\n",
            " 0.00799114 0.01041937 0.0142422  0.01399762 0.00870913 0.0098107\n",
            " 0.03098823 0.00948985 0.0202502  0.01413539 0.01186592 0.01492623\n",
            " 0.01432682 0.01122261 0.01939253 0.02583226 0.01010367 0.01822507\n",
            " 0.00717868 0.01398297 0.0244584  0.01720677 0.01317894 0.02342363\n",
            " 0.01381111 0.00463992 0.00905945 0.01123943]\n",
            "Time taken for 1 epoch 8.451064825057983 sec\n",
            "\n",
            "Epoch 47 Batch 0 Loss [0.04624622 0.00144761 0.00257267 0.0072402  0.00438417 0.00707338\n",
            " 0.00324206 0.00275119 0.00243977 0.1862066  0.0017643  0.00294431\n",
            " 0.00737446 0.00129777 0.00207128 0.00222967 0.00112268 0.00155641\n",
            " 0.00459284 0.00471461 0.00105347 0.00509955 0.00406274 0.00639551\n",
            " 0.00389049 0.00140291 0.00454904 0.00648523 0.00406943 0.15662257\n",
            " 0.00460912 0.00383109 0.00541681 0.00298616 0.09026791 0.00378647\n",
            " 0.00412457 0.00447699 0.00283261 0.00531067 0.03152774 0.0053711\n",
            " 0.00202736 0.00751482 0.00396419 0.00079762 0.00515457 0.0053977\n",
            " 0.00142376 0.09093276 0.0041429  0.00661259 0.00911353 0.00126769\n",
            " 0.00838484 0.00405529 0.0057021  0.0070374  0.0035511  0.00753013\n",
            " 0.00901097 0.00293918 0.00307647 0.00263761]\n",
            "Epoch 47 Loss [0.02428592 0.0212571  0.00985693 0.00958593 0.01381764 0.01860393\n",
            " 0.01100523 0.01130494 0.02011586 0.02298068 0.01145304 0.00834659\n",
            " 0.01801189 0.01030969 0.01136656 0.01392099 0.01107803 0.00516925\n",
            " 0.02343302 0.01169527 0.0102005  0.02715982 0.01746944 0.00743002\n",
            " 0.01901262 0.02232144 0.01592637 0.02046138 0.01967685 0.01872722\n",
            " 0.03043437 0.02304802 0.01132925 0.0132496  0.01290452 0.00427177\n",
            " 0.01283466 0.01257204 0.0101785  0.00725052 0.0081496  0.0235509\n",
            " 0.01472865 0.00669327 0.00662026 0.0178098  0.01378177 0.00516275\n",
            " 0.00955446 0.02495021 0.0239532  0.02212352 0.01112518 0.01278492\n",
            " 0.01500322 0.00517944 0.02256934 0.01707423 0.00796847 0.00812778\n",
            " 0.00542942 0.01043016 0.01146227 0.00777443]\n",
            "Time taken for 1 epoch 8.047344446182251 sec\n",
            "\n",
            "Epoch 48 Batch 0 Loss [0.00148291 0.00357165 0.01226161 0.0031836  0.00392124 0.00166377\n",
            " 0.00207482 0.00234512 0.00832377 0.00742895 0.00322134 0.00300206\n",
            " 0.01183753 0.00207187 0.06460163 0.00125971 0.00261534 0.00444085\n",
            " 0.00252754 0.00111105 0.0068446  0.00456133 0.01002656 0.00303725\n",
            " 0.00114336 0.12601998 0.00550898 0.00536949 0.01357587 0.00558141\n",
            " 0.00331772 0.00194982 0.07312825 0.0023838  0.0092206  0.00126744\n",
            " 0.00599995 0.00452983 0.00348    0.00123607 0.00240171 0.00331398\n",
            " 0.00186098 0.00573796 0.00543422 0.00277816 0.02713215 0.00888476\n",
            " 0.06879751 0.00170555 0.00351034 0.00344621 0.00419096 0.00253819\n",
            " 0.11350243 0.00523532 0.00520187 0.0012397  0.00175557 0.00272489\n",
            " 0.00173618 0.00305484 0.01012044 0.00056677]\n",
            "Epoch 48 Loss [0.00879258 0.01032077 0.02673974 0.01695925 0.01291793 0.0042397\n",
            " 0.01337618 0.0182465  0.01029462 0.01358761 0.01904416 0.01552896\n",
            " 0.01437822 0.00460834 0.01782606 0.01696791 0.02220164 0.01169551\n",
            " 0.01085507 0.01074611 0.00659771 0.02190388 0.01153237 0.0158073\n",
            " 0.01771785 0.03759242 0.02598792 0.01540711 0.00797312 0.02145802\n",
            " 0.02439251 0.01117521 0.0113131  0.01822976 0.02143768 0.01256057\n",
            " 0.01261225 0.02602196 0.00479696 0.02276136 0.00982036 0.00863457\n",
            " 0.01971537 0.01057627 0.01664368 0.01166039 0.02504537 0.00943341\n",
            " 0.01608585 0.01055473 0.01633207 0.01994916 0.00471313 0.01564456\n",
            " 0.01387123 0.01197147 0.00529067 0.00955574 0.01140969 0.008786\n",
            " 0.009932   0.00856151 0.00457812 0.00911993]\n",
            "Time taken for 1 epoch 8.440556526184082 sec\n",
            "\n",
            "Epoch 49 Batch 0 Loss [0.00367373 0.00393056 0.00270301 0.06908889 0.00231457 0.00521634\n",
            " 0.00578012 0.07810101 0.0004077  0.00164702 0.00127926 0.00594663\n",
            " 0.01224784 0.00164338 0.01294634 0.00233664 0.00281276 0.00359489\n",
            " 0.0051806  0.04581101 0.00852311 0.00100198 0.02052348 0.00234815\n",
            " 0.0056158  0.00704745 0.00304177 0.00223505 0.00275794 0.00448653\n",
            " 0.00398101 0.00135045 0.00427942 0.01583879 0.00232886 0.00231814\n",
            " 0.00264763 0.00723678 0.00810045 0.1378444  0.00165462 0.0070892\n",
            " 0.0055844  0.00189498 0.00767817 0.00165203 0.08029108 0.00243334\n",
            " 0.00240122 0.00543278 0.00609587 0.04340336 0.00406422 0.00998037\n",
            " 0.01177751 0.00244366 0.00803711 0.00400334 0.00115496 0.00109576\n",
            " 0.0058948  0.00266379 0.0078605  0.00815719]\n",
            "Epoch 49 Loss [0.01672644 0.00520357 0.00870823 0.01231983 0.01470865 0.01340932\n",
            " 0.01686042 0.02027011 0.01206722 0.0107099  0.01900921 0.01401841\n",
            " 0.01726429 0.00754655 0.00975264 0.00911795 0.0175965  0.00565249\n",
            " 0.01714153 0.01699311 0.00999662 0.01837846 0.01410439 0.01562537\n",
            " 0.0254529  0.02008345 0.01208822 0.0072638  0.02166992 0.00820496\n",
            " 0.00992227 0.01088231 0.01458188 0.00990462 0.0044038  0.0068871\n",
            " 0.00434433 0.01796846 0.01209703 0.02284265 0.02057507 0.0155421\n",
            " 0.01710906 0.00822195 0.01506754 0.00832909 0.01230739 0.01594373\n",
            " 0.0179349  0.01860102 0.00429212 0.00617579 0.0089428  0.00434908\n",
            " 0.01694015 0.01827439 0.00553186 0.01878882 0.01898126 0.00653695\n",
            " 0.01692433 0.01425443 0.02324324 0.01362689]\n",
            "Time taken for 1 epoch 8.076858520507812 sec\n",
            "\n",
            "Epoch 50 Batch 0 Loss [0.00278983 0.00933475 0.00712423 0.00225175 0.00431583 0.00319628\n",
            " 0.0048949  0.00828561 0.10779983 0.00610984 0.00490677 0.00154403\n",
            " 0.0482615  0.0022524  0.00278611 0.00284999 0.00091375 0.00147239\n",
            " 0.00210706 0.00668414 0.00352174 0.00429017 0.00358817 0.00227238\n",
            " 0.00441735 0.00681382 0.00044542 0.00834185 0.00203631 0.00874209\n",
            " 0.00641458 0.00147878 0.00391733 0.00109194 0.008305   0.00171239\n",
            " 0.00407184 0.00037218 0.00306799 0.00313657 0.00203227 0.00233113\n",
            " 0.00302815 0.00708881 0.00246743 0.0071195  0.00289488 0.00268158\n",
            " 0.07169741 0.00378593 0.00394184 0.00508874 0.00214011 0.01158495\n",
            " 0.00791699 0.00493231 0.00139413 0.00088825 0.01163362 0.00446071\n",
            " 0.00250288 0.02717792 0.00700304 0.00824405]\n",
            "Epoch 50 Loss [0.01682709 0.0173946  0.01368775 0.01108431 0.00735255 0.00410568\n",
            " 0.0151276  0.0036189  0.00950934 0.00449013 0.01951947 0.02271537\n",
            " 0.01131906 0.01857472 0.02245062 0.01814297 0.00917629 0.01323649\n",
            " 0.01702064 0.00755076 0.00719165 0.01042048 0.01427202 0.01468238\n",
            " 0.00976409 0.01031495 0.01673468 0.01991638 0.01279258 0.03384637\n",
            " 0.01528843 0.01278449 0.00418439 0.02188748 0.00943902 0.01076044\n",
            " 0.01042986 0.01707658 0.00871517 0.01040697 0.02528265 0.00521337\n",
            " 0.00837912 0.01424421 0.01229979 0.00987705 0.00742418 0.02590621\n",
            " 0.01104429 0.00874986 0.01123594 0.01359523 0.02091146 0.01126232\n",
            " 0.00799938 0.02525583 0.01414254 0.00511481 0.00971507 0.0145653\n",
            " 0.00515868 0.0324178  0.01030642 0.01504375]\n",
            "Time taken for 1 epoch 8.455543756484985 sec\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xstDf5w44fZ"
      },
      "source": [
        "def evaluate(sentence):\r\n",
        "    attention_plot = np.zeros((max_length_targ,max_length_inp))\r\n",
        "    \r\n",
        "    sentence = preprocess_sentence(sentence)\r\n",
        "    inputs = [inp_lang.word_index[i] for i in sentence.split(\" \")]\r\n",
        "    inputs=tf.keras.preprocessing.sequence.pad_sequences([inputs],maxlen=max_length_inp,padding='post')\r\n",
        "    inputs = tf.convert_to_tensor(inputs)\r\n",
        "    result = ''\r\n",
        "    \r\n",
        "    hidden = [tf.zeros((1, units))]\r\n",
        "    enc_out, enc_hidden = encoder(inputs, hidden)\r\n",
        "    dec_hidden = enc_hidden\r\n",
        "    dec_input = tf.expand_dims([targ_lang.word_index['<start>']], 0)\r\n",
        "    for t in range(max_length_targ):\r\n",
        "        predictions, dec_hidden, attention_weights = decoder(dec_input,\r\n",
        "                                                         dec_hidden,\r\n",
        "                                                         enc_out)\r\n",
        "        #storing the attention weights\r\n",
        "        attention_weights = tf.reshape(attention_weights, (-1, ))\r\n",
        "        attention_plot[t] = attention_weights.numpy()\r\n",
        "\r\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\r\n",
        "        result += targ_lang.index_word[predicted_id] + ' '\r\n",
        "        if targ_lang.index_word[predicted_id] == '<end>':\r\n",
        "            return result, sentence, attention_plot\r\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\r\n",
        "    \r\n",
        "    return result, sentence, attention_plot\r\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQFtTr5F_ASH"
      },
      "source": [
        "# function for plotting the attention weights\r\n",
        "def plot_attention(attention, sentence, predicted_sentence):\r\n",
        "    fig = plt.figure(figsize=(10,10))\r\n",
        "    ax = fig.add_subplot(1, 1, 1)\r\n",
        "    ax.matshow(attention, cmap='viridis')\r\n",
        "\r\n",
        "    fontdict = {'fontsize': 14}\r\n",
        "\r\n",
        "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\r\n",
        "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\r\n",
        "\r\n",
        "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\r\n",
        "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\r\n",
        "\r\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqpRQAUD_CZa"
      },
      "source": [
        "def translate(sentence):\r\n",
        "    result, sentence, attention_plot = evaluate(sentence)\r\n",
        "\r\n",
        "    print('Input: %s' % (sentence))\r\n",
        "    print('Predicted translation: {}'.format(result))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jahWjS9-_Dw-",
        "outputId": "7d2a179f-1dd7-4659-8191-3e76998718ea"
      },
      "source": [
        "#restore to the latest checkpoint\r\n",
        "print(tf.train.latest_checkpoint(checkpoint_dir))\r\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training_checkpoints/ckpt-25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f4c92a172b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a6uCjB0_Oxb",
        "outputId": "abe96310-1dde-41e7-9a26-96a4f4b22c5d"
      },
      "source": [
        "translate(u'i love you.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> i love you . <end>\n",
            "Predicted translation: मैं आपसे प्यार करता हूँ। <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnqIoT0-Oriy",
        "outputId": "7f60efb7-244d-4b99-f291-233f7040b7a1"
      },
      "source": [
        "translate(u'Flowers bloom.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> flowers bloom . <end>\n",
            "Predicted translation: फूल खिलते हैं। <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pr-KsmjdOreB",
        "outputId": "d840be26-d9e2-4ba1-92ea-faf0e0c84447"
      },
      "source": [
        "translate(u'A man must work.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> a man must work . <end>\n",
            "Predicted translation: एक आदमी के लिए काम करना ज़रूरी है। <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4X7WAvdOrci",
        "outputId": "0041f2eb-b303-40e4-b9c0-ff8c068291d2"
      },
      "source": [
        "translate(u'Did you miss me?')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> did you miss me ? <end>\n",
            "Predicted translation: मेरी याद आई क्या ? <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqzZXIUeOrW0",
        "outputId": "7cb1bd22-14aa-4cb9-dc85-ce4b72c46d06"
      },
      "source": [
        "translate(u'He came running.')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: <start> he came running . <end>\n",
            "Predicted translation: वह भागते हुए आया। <end> \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHUNOW9DOrSD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shmYnMzqOrQi"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akn3JDf__Sz1"
      },
      "source": [
        "encoder.save_weights(\"encoder_weights2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0EpzvgSOZ4r"
      },
      "source": [
        "decoder.save_weights(\"decoder_weights2\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7M3Sx24tOj2-"
      },
      "source": [
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "rbiynx69SYKg",
        "outputId": "f362d328-d23c-41a8-abf6-1ba7e2ec300f"
      },
      "source": [
        "files.download(\"decoder_weights2.data-00000-of-00001\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_67a7f99c-9883-48ab-b422-8bd0186d6ab8\", \"decoder_weights2.data-00000-of-00001\", 52551194)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1qJrJgqSgdr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}